#!/usr/bin/env python
# Copyright (C) 2013 Ion Torrent Systems, Inc. All Rights Reserved
# pylint: disable=missing-docstring, line-too-long, bad-whitespace, trailing-whitespace

import sys
import os
import subprocess
import json
import shutil
import time
import traceback
import tempfile
import copy
import unicodedata
import pandas as pd
from optparse import OptionParser
from django.conf import settings
from django.template.loader import render_to_string
from ion.utils import compress # provided by ion-pipeline

# critical environment variables:
DIRNAME                     = '' # home directory for the plugin files
TSP_URLPATH_PLUGIN_DIR      = ''
TSP_FILEPATH_PLUGIN_DIR     = ''
STARTPLUGIN_JSON            = {}
BARCODES_JSON               = {}
ANALYSIS_DIR                = ''
OUTPUT_FILES                = []
TVCUTILS                    = 'tvcutils'

# File names generated by the plugin
BASENAME_VARIANTS_XLS       = 'variants.xls'
BASENAME_ALLELES_XLS        = 'alleles.xls'
BASENAME_HOTSPOTS_XLS       = 'allele_counts.xls'
BASENAME_VARIANTS_VCF       = 'TSVC_variants.vcf'
BASENAME_GENOME_VCF         = 'TSVC_variants.genome.vcf'
BASENAME_PARAMETERS_JSON    = 'local_parameters.json'
HTML_BLOCK                  = 'variantCaller_block.html'    # Top report page block
HTML_RESULTS                = 'variantCaller.html'          # Main plugin page
BASENAME_VARIANT_COV_XLS    = 'variant_allele_counts.xls'
NONBARCODED                 = 'nonbarcoded'                 # The "barcode" of a non-barcoded run specified in barcodes.json


# DEVELOPMENT/DEBUG options:
# NOTE: the following should all be set to 0 in production mode
PLUGIN_DEV_KEEP_INTERMEDIATE_FILES = True   # use prior to PLUGIN_DEV_RECALL_VARIANTS=1 to re-process from temporary results
PLUGIN_DEV_SKIP_VARIANT_CALLING = False      # 1 to skip variant calling - use previous calls
SKIP_BAMFILE_VERSION_CHECK = False

# Minimum barcode BAM read counts for variant calling.
BCFILE_MIN_READS = 100

# =======================================================================
# The class handles the options in "one" configuration
class ConfigureOptionsManager:
    def __init__(self, configuration = None): 
        if configuration is not None:
            self.get_options(configuration)
    def serve_option(self, option_key, barcode = None):
        '''
        This function serves the option actually being used.
        Rule: check the barcode-specific option first then go to meta. 
        '''
        # First check the barcode is valid
        if not (barcode is None or barcode in self.__barcodes_options):
            raise ValueError('Unknown barcode %s in the configuration %s' %(barcode, self.configuration_name))
            return None

        if barcode is None:
            return self.__options[option_key]
        else:
            try:
                return self.__barcodes_options[barcode][option_key]
            except KeyError:
                try:
                    return self.__options[option_key]
                except KeyError:
                    pass
        raise KeyError('Unknown option key %s%s.' %(option_key, '' if barcode is None else ' for the barcode %s'%barcode))
        return None

    def add_option(self, option_key, option_value, barcode = None):
        if not (barcode is None or barcode in self.__barcodes_options):
            raise ValueError('Unknown barcode %s in the configuration %s' %self.configuration_name)

        if barcode is None:
            if option_key in self.__barcode_options_keys:
                # I can't add the "global" key that exists locally.
                raise KeyError('The option %s is barcode specific but no barcode is provided.')
            else:
                self.__options[option_key] = option_value
        else:
            self.__barcodes_options[barcode][option_key] = option_value
            self.__barcode_options_keys.update([option_key, ])
        # Sanity check
        assert(option_value == self.serve_option(option_key, barcode))
    
    def get_consensus_option_across_barcodes(self, option_key, skip_error_barcode = False):
        '''
        return is_barcodes_reach_consensus, consensus_option
        '''
        value_list = [self.serve_option(option_key, barcode) for barcode in self.__barcodes_options if ((not skip_error_barcode) or len(self.serve_option('error', barcode)) == 0) ]
        if value_list == []:
            return None, None

        return get_consensus(value_list) 
    
    def chip_type_cleanup(self, my_chip_type):
        my_chip_type = str(my_chip_type).lower()
        if my_chip_type in ['pgm', '314', '316', '318']:
            return 'pgm'
        if my_chip_type in ['510', '520', '530', '540', '550']:
            return my_chip_type
        if 'p1' in my_chip_type or 'proton' in my_chip_type:
            return 'proton_p1'
        return None
    
    def load_parameters(self, configuration):
        json_in = configuration['json']
        try:
            self.__options['parameters'] = copy.deepcopy(json_in['pluginconfig'])
            meta_configuration = self.__options['parameters']['meta']['configuration']
        except:
            if 'barcodes' in json_in['pluginconfig']:
                json_in['pluginconfig']['meta'] = copy.deepcopy(json_in['pluginconfig']['barcodes'][0]['json_in']['pluginconfig']['meta'])
            try:
                self.__options['parameters'] = copy.deepcopy(json_in['pluginconfig'])
                meta_configuration = self.__options['parameters']['meta']['configuration']
            except:
                self.__options['parameters'] = {}

        # Parameter file for the configuration
        if self.configuration_name == '':
            self.__options['parameters_file'] = os.path.join(TSP_FILEPATH_PLUGIN_DIR, BASENAME_PARAMETERS_JSON)
        else:
            # The configuration name in a configured run can not be ""
            # So I shall not see collision of the file names if one configuration named 'local' and one configuration named 'local', assuming BASENAME_PARAMETERS_JSON = 'local_parameters.json'  
            self.__options['parameters_file'] = os.path.join(TSP_FILEPATH_PLUGIN_DIR, '%s_parameters.json' %self.configuration_name)
            
        with open(os.path.join(DIRNAME, 'pluginMedia/parameter_sets/parameter_sets.json'),'r') as fin:
            built_in_parameters = json.load(fin, parse_float=str)
    
        # Handle the reload parameter more carefully since there might be multiple configurations that can replace this configuration.
        # Priorities:
        # P1: The configuration named exactly the same as meta_configuration
        # P2: User selected chip type matched the chip compatibility list
        # P3: runinfo chip type matched the chip compatibility list
        # P4: no chip match
        user_selected_chip = self.chip_type_cleanup(self.__options['parameters'].get('meta', {}).get('user_selections', {}).get('chip', None))
        runinfo_chip = self.chip_type_cleanup(STARTPLUGIN_JSON.get('runinfo', {}).get('chipType', None))
        reload_parameters = None
        best_reload_prioirty = 4
        for try_reload_parameters in built_in_parameters:
            if meta_configuration not in try_reload_parameters["meta"]["replaces"]:
                continue
            # P1
            if meta_configuration == try_reload_parameters['meta']['configuration']:
                best_reload_prioirty = 1
                reload_parameters = try_reload_parameters
                break
            # P2 
            if user_selected_chip in try_reload_parameters['meta']['compatibility']['chip'] and best_reload_prioirty > 2:
                best_reload_prioirty = 2
                reload_parameters = try_reload_parameters
            # P3
            if runinfo_chip in try_reload_parameters['meta']['compatibility']['chip'] and best_reload_prioirty > 3:
                best_reload_prioirty = 3
                reload_parameters = try_reload_parameters
            if best_reload_prioirty == 4:
                reload_parameters = try_reload_parameters
            

        if reload_parameters is not None:    
            self.__options['original_parameters'] = copy.deepcopy(json_in['pluginconfig'])
            self.__options['parameters'] = reload_parameters
    
            if 'meta' not in self.__options['parameters']:
                self.__options['parameters']['meta'] = {}
            if 'configuration' not in self.__options['parameters']['meta']:
                self.__options['parameters']['meta']['configuration'] = meta_configuration
    
            # Handle TS-16890
            if best_reload_prioirty == 1 and json_in['pluginconfig'] == {'meta': {'configuration': meta_configuration}}:
                self.__options["original_config_line1"] = '(Default) %s' % self.__options['parameters']['meta']['name']
                self.__options["original_config_line2"] = '%s, TS version: %s' %(meta_configuration, self.__options['parameters']['meta'].get('ts_version', 'unspecified')) 
            else:
                self.__options["original_config_line1"] = self.__options['original_parameters']['meta'].get('name','Legacy '+ meta_configuration)
                self.__options["original_config_line2"] = ''
                if self.__options['original_parameters']['meta'].get('configuration',''):
                    self.__options["original_config_line2"] += self.__options['original_parameters']['meta']['configuration'] + ', '
                self.__options["original_config_line2"] += 'TS version: ' + self.__options['original_parameters']['meta'].get('ts_version','unspecified')

        self.__options["config_line1"] = self.__options['parameters']['meta'].get('name', 'Legacy %s' %meta_configuration )        
        self.__options["config_line2"] = ''
        if self.__options['parameters']['meta'].get('configuration',''):
            self.__options["config_line2"] += self.__options['parameters']['meta']['configuration'] + ', '
        self.__options["config_line2"] += 'TS version: ' + self.__options['parameters']['meta'].get('ts_version','unspecified')
    
        # Ensure nonstandard unicode characters are eliminated from config_line1, and original_config_line1            
        self.__options["config_line1"] = unicode_cleanup(self.__options["config_line1"])
        if 'original_config_line1' in self.__options:
            self.__options["original_config_line1"] = unicode_cleanup(self.__options["original_config_line1"])
    
        self.__options['parameters']['meta']['tvcargs'] = json_in['pluginconfig']['meta'].get('tvcargs','')
        if not self.__options['parameters']['meta']['tvcargs']:
            self.__options['parameters']['meta']['tvcargs'] = 'tvc'
        # Call tvc -v to get the version string
        tvc_args = self.__options['parameters'].get('meta',{}).get('tvcargs','tvc')
        if tvc_args == 'tvc' and os.path.exists(os.path.join(DIRNAME, 'bin/tvc')):   # try local binary first, then go to global one
            tvc_args = os.path.join(DIRNAME, 'bin/tvc')
        elif tvc_args == 'tmol':
            configuration['error'].append('The plugin does not support the legacy TS-5.2 parameter file that uses "tmol" for tagseq. Please upgrade your run plan and/or parameter file.')
            
        self.__options['tvc_version'] = execute_output(tvc_args + ' -v').splitlines()[0]
        suffix = '- Torrent Variant Caller'
        if self.__options['tvc_version'].endswith(suffix):
            self.__options['tvc_version'] = self.__options['tvc_version'][:-len(suffix)].strip()

        # Check parameter.
        if self.__options['parameters'] == {}:
            configuration['error'].append('Fail to get parameters.')
        for key in ['meta', 'torrent_variant_caller', 'freebayes', 'long_indel_assembler']:
            if key not in self.__options['parameters']:
                configuration['warning'].append('The section "%s" is not found in the parameter file.' %key)
        
        # The default error motifs
        if 'error_motifs' in self.__options['parameters'].get('torrent_variant_caller', {}):
            # Don't use the default error motif if error motif is specified in the parameter file.
            self.__options['error_motifs'] = ''
        else:
            self.__options['error_motifs'] = 'motifset.txt'
            chip_type = json_in.get('expmeta', {}).get('chiptype', '')
            sample_prep_kit = json_in.get('plan', {}).get('samplePrepKitName', '')
            sequence_kit = json_in.get('plan', {}).get('sequencekitname', '')
            if sample_prep_kit == 'Ion AmpliSeq Exome Kit':
                if sequence_kit == 'Ion S5 Sequencing Kit' or (sequence_kit == 'IonProtonIHiQ' and chip_type in ['P1.1.17', '540']):
                    self.__options['error_motifs'] = 'ampliseqexome_germline_p1_hiq_motifset.txt'                
                  
    def get_options(self, configuration):
        self.configuration_name = configuration['name']
        self.__is_barcoded_run = configuration['barcoded_run']
        self.__is_configured_run = configuration['configured_run']
        self.__is_multisample = configuration['multisample']
        self.__start_mode = configuration['start_mode'].lower()
        assert(self.__start_mode in ['manual start', 'auto start'])
        self.__is_auto_start = self.__start_mode == 'auto start'
        self.__options = {} # options from the plugin config
        self.__barcodes_options = {},  # barcode specific options for barcoded run in auto start mode. won't initialize for a non-barcded run.
        self.__barcode_options_keys = set() # set of all keys in barcodes_options[barcode]
        
        json_in = configuration['json']

        # Load parameters
        self.load_parameters(configuration)

        # These two values are needed to display the 'Output Directory' in the HTML pages
        self.__options['plugin_name']               = json_in['runinfo'].get('plugin_name','')
        self.__options['pluginresult']              = json_in['runinfo'].get('pluginresult','')
        self.__options['run_name']                  = json_in['expmeta'].get('run_name','Current run')

        # Note that the files in self.__options come from meta. They may be differ from what are actually being used.
        # The default reference/targets/hotspots files 
        self.__options['reference_genome_name']    = json_in['pluginconfig']['meta'].get('reference', '')
        self.__options['targets_bed_unmerged']     = json_in['pluginconfig']['meta'].get('targetregions', '')
        self.__options['hotspots_bed_unmerged']    = json_in['pluginconfig']['meta'].get('targetloci', '')
    
        # In TS-5.4 and earlier, library type is not barcode specific.
        # Need to clean up library type before load_barcode_info because barcodes will take library_type and trim_reads from meta.
        if self.__is_auto_start:
            self.__options['library_type']             = json_in.get('plan',{}).get('runType', None)
        else:  
            self.__options['library_type']             = json_in['pluginconfig']['meta']['librarytype']        
        self.__cleanup_library_type(configuration['error'])
        
        # Deal with barcode stuffs
        self.__load_barcode_info(configuration)
        
        # Cleanup options: file check, etc.
        self.__cleanup_options()   
    
    def __load_barcode_info(self, configuration):
        self.__barcodes_options = {}
        # get the barcodes used in the configuration
        for bam_dict in configuration['bams']:
            barcode = bam_dict['name']            
            try:
                barcode_dict = BARCODES_JSON[barcode]
            except KeyError:
                configuration['error'].append('Missing barcode information for %s' %barcode)
                continue
            # Error and warning are per-barcode.
            my_barcode_option = {'error': [], 'warning': []}

            # Initialize from the meta. May be overwritten later.
            my_barcode_option['reference_genome_name']    = self.__options['reference_genome_name'] 
            my_barcode_option['targets_bed_unmerged']     = self.__options['targets_bed_unmerged']
            my_barcode_option['hotspots_bed_unmerged']    = self.__options['hotspots_bed_unmerged'] 
            my_barcode_option['sse_bed']                  = ''
              
            # I used "\\BARCODESJSON" in a few unreleased versions. Later I found that jquery sometimes can not get "\\BARCODESJSON" correctly.
            # Now it is ".BARCODESJSON". I still keep '\\BARCODESJSON' in case some internal configuration has it.
            # Handle reference
            if self.is_auto_start() or my_barcode_option['reference_genome_name'] in ['.BARCODESJSON', '\\BARCODESJSON']:
                my_barcode_option['reference_genome_name'] = barcode_dict.get('reference', '')
                my_barcode_option['reference_genome_fasta']= barcode_dict.get('reference_fullpath', '')                
            # Handle target regions
            if self.is_auto_start() or my_barcode_option['targets_bed_unmerged'] in ['.BARCODESJSON', '\\BARCODESJSON']:
                my_barcode_option['targets_bed_unmerged']  = barcode_dict.get('target_region_filepath', '')
                my_barcode_option['sse_bed']               = barcode_dict.get('sse_filepath', '')
            # Handle HS
            if self.is_auto_start() or my_barcode_option['hotspots_bed_unmerged'] in ['.BARCODESJSON', '\\BARCODESJSON']:
                my_barcode_option['hotspots_bed_unmerged'] = barcode_dict.get('hotspot_filepath', '')

            my_barcode_option['nuc_type']              = barcode_dict.get('nucleotide_type', 'DNA').upper()
            self.__barcode_options_keys.update(my_barcode_option.keys())
            self.__barcodes_options[barcode] = my_barcode_option

    def is_auto_start(self):
        return self.__is_auto_start
    
    def is_barcoded_run(self):
        return self.__is_barcoded_run
    
    def is_multisample(self):
        return self.__is_multisample
    
    def get_option_dict(self, barcode):
        '''
        Get options of the barcode, including meta and barcode-specific.
        '''
        all_keys = self.__barcode_options_keys.union(self.__options.keys()) 
        option_dict = dict([(key, self.serve_option(key, barcode)) for key in all_keys])
        return option_dict

    def __cleanup_options(self):
            # check the files for barcodes
        for barcode in self.__barcodes_options:
            # cleanup the options for each barcode
            self.__check_options(barcode)
        
        # These keys are not part of the parameter set
        for key in ['librarytype', 'targetregions_id', 'targetregions', 'targetregions_merge', 'targetloci_id', 'targetloci', 'targetloci_merge', 'user_selections']:
            self.__options['parameters']['meta'].pop(key, None)


    def __check_options(self, barcode):
        '''
        Check option for the barcode
        '''
        options = self.__barcodes_options[barcode]
        options['reference_genome_fai'] = ""
        options['targets_name']         = ""
        options['targets_bed_merged']   = ""
        options['has_targets']          = False
        options['hotspots_name']        = ""
        options['hotspots_bed_merged']  = ""
        options['has_hotspots']         = False
        options['has_sse_bed']          = False
        options['trim_reads']           = self.__options['library_type'] in ['AmpliSeq']
        # check referemce genome
        if not options['reference_genome_name']:
            options['error'].append('Reference genome unspecified.')
        else:
            if not options.get('reference_genome_fasta', ''): 
                options['reference_genome_fasta'] = os.path.join(os.path.join('/results/referenceLibrary/tmap-f3/', options['reference_genome_name']), options['reference_genome_name'] + '.fasta') 
            options['reference_genome_fai'] = '%s.fai' %options['reference_genome_fasta']
    
        # Check target region bed files
        if not options['targets_bed_unmerged'] or options['targets_bed_unmerged'].lower() == "none":
            options['targets_bed_unmerged']     = ""
            options['targets_bed_merged']       = ""
            options['targets_name']             = ""
            options['trim_reads']               = False
        else:
            options['targets_bed_merged']       = options['targets_bed_unmerged'].replace('/unmerged/detail/', '/merged/plain/')
            if options['targets_bed_unmerged'].lower().endswith('.bed'):
                options['targets_name']             = os.path.basename(options['targets_bed_unmerged'])[:-4]
            else:
                options['targets_name']             = os.path.basename(options['targets_bed_unmerged'])
                options['error'].append('Target bed file does not ends with .bed')
        options['has_targets'] = options['targets_bed_unmerged']  != ""
        if options['has_targets'] and '/%s/' %options['reference_genome_name'] not in options['targets_bed_unmerged']:
            # Assumption: the target file is in /results/BED/{xx}/{ref}/unmerged/detail/...
            options['error'].append('The target bed file %s is not for the reference genome %s.' %(options['targets_bed_unmerged'], options['reference_genome_name']))    
    
        # Check hotspots bed files
        if (not options['hotspots_bed_unmerged']) or options['hotspots_bed_unmerged'].lower() == "none":
            options['hotspots_bed_unmerged']    = ""
            options['hotspots_bed_merged']      = ""
            options['hotspots_name']            = ""  
        else:
            options['hotspots_bed_merged']      = options['hotspots_bed_unmerged'].replace('/unmerged/detail/', '/merged/plain/')
            if options['hotspots_bed_merged'].lower().endswith('.bed'):
                options['hotspots_name']            = os.path.basename(options['hotspots_bed_unmerged'])[:-4]
            else:
                options['hotspots_name']            = os.path.basename(options['hotspots_bed_unmerged'])
                options['error'].append('Hotspot bed file does not ends with .bed')
        options['has_hotspots'] = options['hotspots_bed_unmerged'] != ""
        if options['has_hotspots'] and '/%s/' %options['reference_genome_name'] not in options['hotspots_bed_unmerged']:
            # Assumption: the target file is in /results/BED/{xx}/{ref}/unmerged/detail/...
            options['error'].append('The Hotspots bed file %s is not for the reference genome %s.' %(options['targets_bed_unmerged'], options['hotspots_bed_unmerged']))          
    
        # Check SSE bed file
        if (options['sse_bed'] == '') and options['has_targets']:
            # Assumption: if exists, the SSE bed file locates at the same dir as the unmerged target bed file does. The basename of the SSE bed follows the naming convention that panel.date.type.bed where type = mask.
            split_targets_basename = os.path.basename(options['targets_bed_unmerged']).split('.')
            split_targets_basename[-2] = 'mask'
            try_sse_bed_path = os.path.join(os.path.dirname(options['targets_bed_unmerged']), '.'.join(split_targets_basename))
            if os.path.exists(try_sse_bed_path):
                options['sse_bed'] = try_sse_bed_path
        options['has_sse_bed'] = options['sse_bed'] != ''
        if options['has_sse_bed'] and (not options['has_targets']): 
            options['error'].append('SSE bed file must have a valid target bed file.')

        # Check existance of the files    
        for key in ['reference_genome_fasta', 'reference_genome_fai', 'targets_bed_unmerged', 'targets_bed_merged', 'hotspots_bed_unmerged', 'hotspots_bed_merged', 'sse_bed']:
            if options[key] != '' and (not os.path.exists(options[key])):
                options['error'].append('Can not find the %s file: %s' %(key.replace('_', ' '), options[key]))
    
        if self.__options['library_type'] in ["AmpliSeq", 'tagseq', 'ampliseq_hd'] and not options['has_targets']:
            options['error'].append('A %s run must have target regions specified' %self.__options['library_type'])
            
        # Note that I may add more keys in check_options. So I MUST update self.__barcode_options_keys
        self.__barcode_options_keys.update(options.keys())
    
    def __cleanup_library_type(self, error_msg_list):
        # In TS-5.4 and earlier, library_type is not barcode specific.
        my_lib_type = self.__options['library_type'].lower()
        self.__options['has_umt'] = False
        if my_lib_type in [v.lower() for v in ["wholegenome",'WGNM','GENS']]:
            self.__options['library_type'] = "Whole Genome"
        elif my_lib_type in [v.lower() for v in ["ampliseq",'AMPS','AMPS_EXOME','AMPS_DNA_RNA','AMPS_DNA']]:
            self.__options['library_type'] = "AmpliSeq"
        elif my_lib_type in [v.lower() for v in ["targetseq",'TARS']]:
            self.__options['library_type'] = "TargetSeq"
        elif my_lib_type in [v.lower() for v in ["tagseq", 'tag_sequencing', 'TAG_SEQUENCING']]:
            self.__options['library_type'] = "tagseq"
            self.__options['has_umt'] = True
        elif my_lib_type.startswith('AMPS_HD'.lower()) or my_lib_type == 'ampliseq_hd':
            self.__options['library_type'] = 'ampliseq_hd'
            self.__options['has_umt'] = True
        elif not my_lib_type:
            error_msg_list.append('Empty library type from the plan')
        else:
            error_msg_list.append('Unknown library type: %s' %self.__options['library_type'])

# End of class ConfigureOptionsManager
# =======================================================================
    
def printtime(message, *args):
    if args:
        message = message % args
    print "[ " + time.strftime('%a %Y-%m-%d %X %Z') + " ] " + message
    sys.stdout.flush()
    sys.stderr.flush()


def unicode_cleanup(message):
    try:
        return str(message)
    except:
        return unicodedata.normalize('NFKD',unicode(message)).encode('ascii','ignore')

def run_command(command,description):
    printtime(' ')
    printtime('Task    : ' + description)
    printtime('Command : ' + command)
    printtime(' ')
    return subprocess.call(command,shell=True)

def execute_output(cmd):
    try:
        process = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True)
        return process.communicate()[0]
    except:
        traceback.print_exc()
        return ''


def generate_incomplete_report_page(output_html_filename, message, run_name, autorefresh=False):
    render_context = { 'run_name' : run_name, 
                       'message' : message, 
                       'autorefresh' : autorefresh,
                       'startplugin_json' : STARTPLUGIN_JSON}

    with open(output_html_filename,'w') as out:
        out.write(render_to_string('report_incomplete.html', render_context))


def generate_incomplete_report_block_page(output_html_filename, error_message, warning_message = ''):
    output_dir = os.path.basename(TSP_FILEPATH_PLUGIN_DIR.rstrip('/'))
    render_context = { 'output_dir' : output_dir,
                       'error_msg' : error_message,
                       'warning_msg': warning_message,
                       'startplugin_json': STARTPLUGIN_JSON,
                    }

    with open(output_html_filename,'w') as out:
        out.write(render_to_string('report_incomplete_block.html', render_context))    


def generate_barcode_links_block(block_html_path, process_status, vc_options, error_msg = '', warning_msg = ''):
    output_dir = os.path.basename(TSP_FILEPATH_PLUGIN_DIR.rstrip('/'))
    render_context = {
        'barcode_data'          : process_status['bams_processed'],
        'output_dir'            : output_dir,
        'options'               : vc_options,
        'startplugin_json'      : STARTPLUGIN_JSON,
        'error_msg'             : error_msg,
        'warning_msg'           : warning_msg,
    }

    with open(block_html_path,'w') as out:
        out.write(render_to_string('block_barcodes.html', render_context))

def generate_barcode_links_page (results_html_path, process_status, vc_options, error_msg = '',  warning_msg = ''):
    output_dir = os.path.basename(TSP_FILEPATH_PLUGIN_DIR.rstrip('/'))    
    render_context = {
        'barcode_data'          : process_status['bams_processed'],
        'output_dir'            : output_dir,
        'options'               : vc_options,
        'autorefresh'           : False,
        'startplugin_json'      : STARTPLUGIN_JSON,
        'error_msg'             : error_msg,
        'warning_msg'           : warning_msg,
    }

    for barcode in process_status['bams_processed']:
        if barcode['status'] == 'in_progress':
            render_context['autorefresh'] = True

    with open(results_html_path, 'w') as out:
        out.write(render_to_string('report_barcodes.html', render_context))


def add_output_file(file_type, filename, barcode=None, sample=None):
    file_info = {
        'type' : file_type,
        'filename' : os.path.basename(filename),
        'server_path' : os.path.join(TSP_FILEPATH_PLUGIN_DIR,filename),
        'download_path' : os.path.join(TSP_URLPATH_PLUGIN_DIR,filename)
    }
    if barcode is not None:
        file_info['barcode'] = barcode
    if sample is not None:
        file_info['sample'] = sample

    OUTPUT_FILES.append(file_info)

def package_vcf(vcf_file):
    run_command('bgzip -c ' + vcf_file + ' > ' + vcf_file + '.gz', 'Generate compressed vcf')
    run_command('tabix -p vcf ' + vcf_file + '.gz', 'Generate index for compressed vcf')

def is_empty_vcf(vcf_path):
    #empty_vcf = True
    try:
        with open(vcf_path, 'r') as f_vcf:
            for line in f_vcf:
                if not line or line.startswith('#'):
                    continue
                return False
    except:
        traceback.print_exc()
        raise IOError
    return True
    
def prepare_target_regions(options, queued_bams):
    barcode = queued_bams[0]['name']
    if not options.serve_option('has_targets', barcode):
        return

    source_target_path = options.serve_option('targets_bed_unmerged', barcode)
    # Make sure that the target region file is for the reference genome.
    # Assumption: path of unmerged target region is under /(reference name)/unmerged/detail/
    if '/%s/unmerged/detail/'%options.serve_option('reference_genome_name', barcode) not in source_target_path:
        raise ValueError('The bed file %s is not for the reference genome %s'%(source_target_path, options.serve_option('reference_genome_name', barcode)))
    local_target_path = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(source_target_path))
    # make a copy of Target Bed to the plugin dir
    if not os.path.exists(local_target_path):
        shutil.copy(source_target_path, local_target_path)
        add_output_file('target_regions_bed', os.path.basename(source_target_path))
    symlink_target_path_list = [os.path.join(bam['results_directory'], os.path.basename(source_target_path)) for bam in queued_bams]
    symlink_target_path_list.append(os.path.join(queued_bams[0]['vc_pipeline_directory'], os.path.basename(source_target_path)))
    for symlink_target_path in symlink_target_path_list:
        if not os.path.exists(symlink_target_path):
            os.symlink(source_target_path, symlink_target_path)     
            
def prepare_sse_mask(options, queued_bams):
    barcode = queued_bams[0]['name']
    if not options.serve_option('has_sse_bed', barcode):
        for bam in queued_bams:
            options.add_option('sse_vcf', '', bam['name'])      
        return
    elif not options.serve_option('has_targets', barcode):
        raise ValueError('SSE bed file must come with a target bed file.')    

    sse_bed_path = options.serve_option('sse_bed', barcode)
    assert(sse_bed_path.endswith('.bed'))
    
    if '/%s/'%options.serve_option('reference_genome_name', barcode) not in sse_bed_path:
        raise ValueError('The bed file %s is not for the reference genome %s'%(sse_bed_path, options.serve_option('reference_genome_name', barcode)))
    
    validated_sse_bed = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(sse_bed_path))
    validated_sse_bed = validated_sse_bed[:-4] + '.validated.bed'
    sse_vcf = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(sse_bed_path))
    sse_vcf = sse_vcf[:-4] + '.vcf'    

    local_sse_bed_path = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(sse_bed_path))
    is_valid_sse_vcf = True
    if not os.path.exists(local_sse_bed_path):
        shutil.copy(sse_bed_path, local_sse_bed_path)

    if not os.path.exists(sse_vcf):         
        validate_sse_bed_command  = '%s validate_bed ' %TVCUTILS
        validate_sse_bed_command += ' --reference %s ' %options.serve_option('reference_genome_fasta', barcode)
        validate_sse_bed_command += ' --hotspots-bed %s ' %sse_bed_path
        validate_sse_bed_command += ' --unmerged-detail-bed %s ' %validated_sse_bed
        run_command(validate_sse_bed_command, 'Validating SSE bed file ...')
        
        if os.path.exists(validated_sse_bed):
            prepare_sse_vcf_command  = '%s prepare_hotspots ' %TVCUTILS
            prepare_sse_vcf_command += ' --reference %s '    %options.serve_option('reference_genome_fasta', barcode)
            prepare_sse_vcf_command += ' --input-bed %s '    %validated_sse_bed
            prepare_sse_vcf_command += ' --unmerged-bed %s ' %options.serve_option('targets_bed_unmerged', barcode)
            prepare_sse_vcf_command += ' --output-vcf %s '   %sse_vcf
            run_command(prepare_sse_vcf_command, 'Generating SSE vcf file ...')
        else:
            is_valid_sse_vcf = False
    
    if is_valid_sse_vcf:
        is_valid_sse_vcf = not is_empty_vcf(sse_vcf)
    
    if is_valid_sse_vcf:
        for bam in queued_bams:
            options.add_option('sse_vcf', sse_vcf, bam['name'])

        symlink_sse_path_list = [os.path.join(bam['results_directory'], os.path.basename(sse_vcf)) for bam in queued_bams]
        symlink_sse_path_list.append(os.path.join(queued_bams[0]['vc_pipeline_directory'], os.path.basename(sse_vcf)))
        for symlink_sse_path in symlink_sse_path_list:
            if not os.path.exists(symlink_sse_path):
                os.symlink(sse_vcf, symlink_sse_path)
    else:
        printtime('Warning: The SSE bed file %s has no valid alleles. Disable the use of SSE file in tvc.' %(sse_bed_path))
        for bam in queued_bams:
            options.add_option('sse_vcf', '', bam['name'])
            bam['warning'].append('The SSE bed file %s has no valid alleles. Disable the use of SSE file in tvc.' %options.serve_option('sse_bed', bam['name']))
 
def prepare_hotspots(options, queued_bams):
    # The case of more than one bam files must be multisample where all barcodes use the same HS file.
    barcode = queued_bams[0]['name']
    hotspots_bed_unmerged_path = options.serve_option('hotspots_bed_unmerged', barcode)
    for bam in queued_bams:
        assert(options.serve_option('hotspots_bed_unmerged', bam['name']) == hotspots_bed_unmerged_path)
    
    if not options.serve_option('has_hotspots', barcode):
        for bam in queued_bams:
            options.add_option('hotspots_bed_unmerged_leftalign', '', bam['name'])
            options.add_option('hotspots_vcf', '', bam['name'])
            options.add_option('hotspots_bed_unmerged_local', '', bam['name'])        
        return
        
    # Make sure that the HS file is for the reference genome.
    # Assumption: path of unmerged HS is under /(reference name)/unmerged/detail/
    if '/%s/'%options.serve_option('reference_genome_name', barcode) not in hotspots_bed_unmerged_path:
        raise ValueError('The bed file %s is not for %s'%(options.serve_option('reference_genome_name', barcode) , hotspots_bed_unmerged_path))
        
    # create 3 files in TSP_FILEPATH_PLUGIN_DIR and re-evaluate 'has_hotspots' and 'hotspots_vcf'
    # raise an error if fail to open the hotspots files
    try:
        with open(hotspots_bed_unmerged_path, 'r') as f_hs:
            pass
        
        with open(options.serve_option('hotspots_bed_merged', barcode), 'r') as f_hs:
            pass
    except:
        traceback.print_exc()
        raise IOError
        
    hotspots_bed_unmerged_local     = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(hotspots_bed_unmerged_path))
    hotspots_bed_unmerged_leftalign = os.path.join(TSP_FILEPATH_PLUGIN_DIR, options.serve_option('hotspots_name', barcode) + '.left.bed')
    hotspots_vcf                    = os.path.join(TSP_FILEPATH_PLUGIN_DIR, options.serve_option('hotspots_name', barcode) + '.hotspot.vcf')

    if not os.path.exists(hotspots_bed_unmerged_local):
        shutil.copy(hotspots_bed_unmerged_path, hotspots_bed_unmerged_local)
        prepare_hotspots_command  = '%s prepare_hotspots' %TVCUTILS
        prepare_hotspots_command += '  --input-bed "%s"' % hotspots_bed_unmerged_path
        prepare_hotspots_command += '  --reference "%s"' % options.serve_option('reference_genome_fasta', barcode)
        prepare_hotspots_command += '  --left-alignment on'
        prepare_hotspots_command += '  --allow-block-substitutions on'
        prepare_hotspots_command += '  --output-bed "%s"' % hotspots_bed_unmerged_leftalign
        prepare_hotspots_command += '  --output-vcf "%s"' % hotspots_vcf
        if options.serve_option('has_targets', barcode):
            prepare_hotspots_command += '  --unmerged-bed "%s"' % options.serve_option('targets_bed_unmerged', barcode)
        run_command(prepare_hotspots_command, 'Generate filtered, left-aligned, and merged hotspot VCF file')

        if is_empty_vcf(hotspots_vcf):
            printtime('Warning: Filtered hotspot file %s has no hotspot entries. Disabling the use of the hotspots file.' %(hotspots_vcf))
            hotspots_vcf = ''
        else:
            #run_command('bgzip -c %s/hotspot.vcf > %s/hotspot.vcf.gz' % (TSP_FILEPATH_PLUGIN_DIR,TSP_FILEPATH_PLUGIN_DIR), 'Generate compressed hotspot vcf')
            #run_command('tabix -p vcf %s/hotspot.vcf.gz' % (TSP_FILEPATH_PLUGIN_DIR), 'Generate index for compressed hotspot vcf')
            add_output_file('hotspots_bed', os.path.basename(hotspots_bed_unmerged_path))

    for bam in queued_bams:
        options.add_option('hotspots_bed_unmerged_leftalign', hotspots_bed_unmerged_leftalign, bam['name'])
        options.add_option('hotspots_vcf', hotspots_vcf, bam['name'])
        options.add_option('hotspots_bed_unmerged_local', hotspots_bed_unmerged_local, bam['name'])
        if not hotspots_vcf:
            bam['warning'].append('The hotspot file %s has no valid hotspot alleles. Disable the use of hotspots file in tvc.' %hotspots_bed_unmerged_path)
        else:
            # link the HS vcf to local dir.
            hs_vcf_local = os.path.join(bam['vc_pipeline_directory'], os.path.basename(hotspots_vcf))
            if not os.path.exists(hs_vcf_local):
                os.symlink(hotspots_vcf, hs_vcf_local)
            hs_vcf_local = os.path.join(bam['results_directory'], os.path.basename(hotspots_vcf))
            if not os.path.exists(hs_vcf_local):
                os.symlink(hotspots_vcf, hs_vcf_local)                
            

def parse_to_dict(filein,sep=None):
    ret = {}
    if os.path.exists(filein):
        with open(filein) as fin:
            for line in fin:
                line = line.strip()
                # ignore lines being with non-alphanum (for comments, etc)
                if line == "" or not line[0].isalnum():
                    continue
                kvp = line.split(sep,1)
                if len(kvp) > 1:
                    ret[kvp[0].strip()] = kvp[1].strip()
    else:
        printtime("parse_to_dict() could not open "+filein)
    return ret

   
def run_tmap(tmap_cmd, realigned_bam_path):
    success = False
    assert(realigned_bam_path.endswith('.bam'))
    
    # command string contains executable from json args.
    # Replace with executable in bin directory if it's a system executable call
    if tmap_cmd.startswith('tmap ') and TMAPBIN != 'tmap':
        tmap_cmd = TMAPBIN + tmap_cmd[4:]
    
    try:
        tmap_cmd += " | samtools sort -m 1000M -l1 -@12 - %s" %realigned_bam_path[:-4]
        if PLUGIN_DEV_SKIP_VARIANT_CALLING:
            printtime('Skipping realignment of the bam file.') 
            printtime('Command: %s' %tmap_cmd)
            return True
        run_command(tmap_cmd, "Realign the bam file.")
        
        index_cmd = "samtools index %s" %realigned_bam_path
        run_command(index_cmd, "Index the bam file.")
        
        mark_duplicates = False
        with open(os.path.join(ANALYSIS_DIR, 'ion_params_00.json'),'r') as fin:
            plan_data = json.load(fin, parse_float=str)
            mark_duplicates = plan_data.get('experimentAnalysisSettings',{}).get('isDuplicateReads',False)
        printtime("mark_duplicates = %s" %str(mark_duplicates))
        if mark_duplicates:
            temp_realigned_bam_path = realigned_bam_path + ".temp.bam"
            os.rename(realigned_bam_path,temp_realigned_bam_path)
            os.rename(realigned_bam_path+'.bai',temp_realigned_bam_path+'.bai')            
            
            cmd = "BamDuplicates -i %s -o %s" %(temp_realigned_bam_path, realigned_bam_path)
            run_command(cmd, "Mark duplicates")

            cmd = "samtools index %s" %realigned_bam_path
            run_command(cmd, "Indexing bam file")
            
            # And clean up temp files
            os.remove(temp_realigned_bam_path)
            os.remove(temp_realigned_bam_path+'.bai')
        success = True
    except:
        success = False
    return success

def cmd_args_to_dict_items(cmd_args):
    args_dict_items = []
    splitted_cmd_args = cmd_args.split()
    
    for index, value in enumerate(splitted_cmd_args):
        if value == '':
            continue
        if value.startswith('-'):
            try:
                if not splitted_cmd_args[index + 1].startswith('-'):
                    args_dict_items.append((value, splitted_cmd_args[index + 1]))
                else:
                    args_dict_items.append((value, ''))
            except IndexError:
                args_dict_items.append((value, ''))
        else:
            if index == 0:
                args_dict_items.append((value, ''))
            elif not splitted_cmd_args[index - 1].startswith('-'):
                args_dict_items.append((value, ''))
    return args_dict_items

def cmd_args_to_dict(cmd_args):
    return dict(cmd_args_to_dict_items(cmd_args))

def get_pg_cmd_from_header(bam_path, pg_id):
    '''
    Read the Command Line (CL) of the PG with ID from the header of the bam file.
    '''
    cl = ''
    splitted_line = []
    bam_header = execute_output('samtools view -H %s' %bam_path)
    if not bam_header:
        printtime('ERROR: Fail to read the header from %s' %bam_path)        
        return cl

    for line in bam_header.split('\n'):
        if line.startswith('@PG\tID:%s\t'%pg_id):
            splitted_line = line.split('\t')
            break
    for value in splitted_line:
        if value.startswith('CL:'):
            cl = value[3:]
            break
    return cl

def cleanup_cmd(my_cmd):
    my_cmd = ' '.join(my_cmd.split())
    return my_cmd

def get_realign_cmd(bam, realigned_bam_path, planned_tmap_args, desirable_tmap_args, options, tmap_server_key):
    
    if desirable_tmap_args == '':
        # desirable_tmap_args is not provided but I decided to do realignnment
        # This means change of reference and/or target bed file.
        desirable_tmap_args = planned_tmap_args    
                
    # Get the tmap args from the header
    # Note that I take the first (and it should be the only) tmap command!
    tamp_cl_in_header = get_pg_cmd_from_header(bam['file'], 'tmap')
    if tamp_cl_in_header == '':
        printtime('ERROR: Fail to get the tmap command line from the header of %s' %bam['file'])
        return ''
    if not tamp_cl_in_header.startswith('tmap'):
        tamp_cl_in_header = 'tmap %s' %tamp_cl_in_header

    # Clean-up the tmap command lines
    planned_tmap_args = cleanup_cmd(planned_tmap_args)
    desirable_tmap_args = cleanup_cmd(desirable_tmap_args)
    tamp_cl_in_header = cleanup_cmd(tamp_cl_in_header)

    printtime('Tmap args of %s: %s' %(bam['file'], tamp_cl_in_header))
    printtime('Planned tmap args: %s' %planned_tmap_args)
    printtime('Desirable tmap args: %s' %desirable_tmap_args)
    
    # clean up the --bed-file option in planned args
    dummy_bed = ' --bed-file foo.bed ' if ' --bed-file ' in tamp_cl_in_header else ' '
    planned_tmap_args = planned_tmap_args.replace(' --bed-file ', dummy_bed)
    # clean up the --bed-file option in desirable args
    desireable_bed_file = ' --bed-file %s ' %options.serve_option('targets_bed_unmerged', bam['name']) if options.serve_option('has_targets', bam['name']) else ' '
    desirable_tmap_args = desirable_tmap_args.replace(' --bed-file ', desireable_bed_file)        

    # Assumption: planned_tmap_args = XXX + ' ... ' + YYY gives tamp_cl_in_header =  XXX + additional_args + YYY
    planned_args_dict = cmd_args_to_dict(planned_tmap_args.replace(' ... ', ' '))
    # Remove the args in XXX and YYY from tamp_cl_in_header gives additional_args
    additional_args_dict = cmd_args_to_dict(tamp_cl_in_header)
    # The tmap arg I want to use to realign the bam
    desirable_tmap_args_dict = cmd_args_to_dict(desirable_tmap_args)        

    for key in planned_args_dict:
        if key in ['-q', '--reads-queue-size'] and (key not in desirable_tmap_args_dict):
            #  I should keep '-q' unless it is specified in desirable_tmap_args.
            continue
        additional_args_dict.pop(key, None)

    # Clean-up additional_args_dict.
    for key in ['tmap',
                '-f', '--fn-fasta', 
                '-r', '--fn-reads', 
                '-s', '--fn-sam', 
                '-k', '--shared-memory-key',
                '--bam-start-vfo',
                '--bam-end-vfo']:
        # Clean-up the file I/O options and tmap server option
        additional_args_dict.pop(key, None)

    # TS-15287 Handle the case of empty planned_tmap_args  
    if planned_tmap_args == '':
        for key in additional_args_dict.keys():
            if key not in ['-i', '--reads-format', 
                           '-v', '--verbose',
                           '-q', '--reads-queue-size',
                           '-Y', '--sam-flowspace-tags',
                           '-u', '--rand-read-name', 
                           '--prefix-exclude',
                           '-o', '--output-type',
                           '-n', '--num-threads']:
                additional_args_dict.pop(key, None)        
        
    # Finally, anything shows up in desirable_tmap_args_dict should not be in additional_args.
    for key in desirable_tmap_args_dict:
        additional_args_dict.pop(key, None)

    # Now fill the "..." in desirable_tmap_args
    desirable_dot_dot_dot_args = ' '
    if tmap_server_key != 0:
        desirable_dot_dot_dot_args += '-k %s ' %str(tmap_server_key)
    desirable_dot_dot_dot_args += '-f %s -r %s ' %(options.serve_option('reference_genome_fasta', bam['name']), bam['file'])
    for key, value in additional_args_dict.iteritems():
        desirable_dot_dot_dot_args += '%s %s ' %(key, value)
    
    tmap_cmd = desirable_tmap_args.replace(' ... ', desirable_dot_dot_dot_args)
    tmap_cmd = cleanup_cmd(tmap_cmd)
    return tmap_cmd
    
def combine_files(combinedfilename, myfile):
    try:
        file_in = open(myfile, "r")
        if os.path.isfile(combinedfilename):
            file_out = open(combinedfilename, "a")
            for line in file_in:
                if not line.startswith("#"): 
                    file_out.write(line)
            file_out.close()
        else:
            file_out = open(combinedfilename, "w")
            for line in file_in:
                file_out.write(line)
            file_out.close()
        file_in.close()
    except:
        pass

def print_options(vc_options, bam):
    barcode = bam['name']
    print_name = barcode if barcode != NONBARCODED else 'rawlib.bam'
    printtime('')
    printtime('%s: Variant Caller plugin run options:' %print_name)
    printtime('  Plugin name                : %s' %STARTPLUGIN_JSON['runinfo'].get('plugin_name',''))
    printtime('  Plugin start mode          : %s' %('Auto start' if vc_options.is_auto_start() else 'Manual start'))
    printtime('  Variant Caller version     : %s' %vc_options.serve_option('tvc_version'))
    printtime('  Run is barcoded            : %s' %str(vc_options.is_barcoded_run()))
    pretty_library = vc_options.serve_option('library_type', barcode)
    if pretty_library == 'tagseq':
        pretty_library = 'Tag Sequencing'
    elif pretty_library == 'ampliseq_hd':
        pretty_library = 'AmpliSeq HD'
    printtime('  Library Type               : %s'%pretty_library)
    try:  
        printtime('  Requested Parameters       : %s' %vc_options.serve_option("original_config_line1"))
        printtime('                               %s' %vc_options.serve_option("original_config_line2"))
        printtime('  Auto-Updated Parameters    : %s' %vc_options.serve_option("config_line1"))
        printtime('                               %s' %vc_options.serve_option("config_line2"))
    except:
        printtime('  Used Parameters            : %s' %vc_options.serve_option('config_line1'))
        printtime('                               %s' %vc_options.serve_option("config_line2"))
    printtime('  Multi-sample               : %s' %str(vc_options.is_multisample()))
    
        
    warning_list = vc_options.serve_option('warning', barcode)
    if warning_list != []:
        printtime('')        
        printtime('%s: options wanrning:' %print_name)
    for warning_msg in warning_list:
        printtime('  WARNING:                     : %s' %(warning_msg))
                
    error_list = vc_options.serve_option('error', barcode)
    if error_list != []:
        printtime('')        
        printtime('%s: options error:' %print_name)
    for error_msg in error_list:
        printtime('  ERROR:                     : %s' %(error_msg))

    printtime('')
    if error_list != []:
        return
    
    printtime('%s: options applied:' %print_name)
    printtime('  Rawlib bam file            : %s' %bam['file'])    
    printtime('  Reference Genome           : %s' %vc_options.serve_option('reference_genome_fasta', barcode))
    printtime('  Parameters file            : %s' %vc_options.serve_option('parameters_file', barcode))
    try:
        printtime('  Parameters source file     : %s' %vc_options.serve_option('parameters_source', barcode))        
    except:
        pass

    if vc_options.serve_option('has_targets', barcode):
        printtime('  Target unmerged BED        : %s' %vc_options.serve_option('targets_bed_unmerged', barcode))
        printtime('  Target merged BED          : %s' %vc_options.serve_option('targets_bed_merged', barcode))
    else:
        printtime('  Target unmerged BED        : Not using')
        printtime('  Target merged BED          : Not using' )
    if vc_options.serve_option('has_hotspots', barcode): 
        printtime('  Hotspots unmerged BED      : %s' %vc_options.serve_option('hotspots_bed_unmerged', barcode)) 
        printtime('  Hotspots merged BED        : %s' %vc_options.serve_option('hotspots_bed_merged', barcode))
    else:
        printtime('  Hotspots unmerged BED      : Not using') 
        printtime('  Hotspots merged BED        : Not using')
    if vc_options.serve_option('has_sse_bed', barcode): 
        printtime('  SSE BED                    : %s' %vc_options.serve_option('sse_bed', barcode))
    else:
        printtime('  SSE BED                    : Not using')        
    if vc_options.serve_option('error_motifs', barcode) != '':
        printtime('  Error Motif                : %s' %vc_options.serve_option('error_motifs', barcode))
    else:
        printtime('  Error Motif                : As specified in the parameter file.')

    printtime('  Trim Reads                 : %s' %str(vc_options.serve_option('trim_reads', barcode)))
    printtime('')

def is_multisample_ok(options):
    # For multisample, I require all barcodes must have the same
    # 1) hotspots, 2) target regions, 3) reference genome, 4) trim reads (depending on library type), 5) sse bed 
    if options.is_multisample():
        multisample_ok = True
        for key in ['targets_bed_unmerged', 'hotspots_bed_unmerged', 'reference_genome_name', 'trim_reads', 'library_type', 'sse_bed']:
            if not options.get_consensus_option_across_barcodes(key)[0]:
                multisample_ok = False
                printtime('ERROR: Barcodes can not have different "%s" in the multisample mode.' %key)
        if options.get_consensus_option_across_barcodes('error')[1] != []:
            multisample_ok = False        
        return multisample_ok
    return True

def get_plugin_mode():
    barcoded_run = NONBARCODED not in BARCODES_JSON # Now the plugin looks at barcodes.json
    configured_run = 'barcodes' in STARTPLUGIN_JSON['pluginconfig']
    # Determine Start Mode
    start_mode = 'Auto start'
    if configured_run:
        # In TS 5.4 and earily, a configured run must be manually started.
        start_mode = 'Manual start'
    else:
        is_reference_specified_in_meta = (STARTPLUGIN_JSON['pluginconfig'].get('meta', {}).get('reference', '') != '')
        if is_reference_specified_in_meta:
            start_mode = 'Manual start'
    multisample = STARTPLUGIN_JSON['pluginconfig'].get('multisample', False)
    return barcoded_run, configured_run, start_mode, multisample

def filter_barcode(barcode_dict):
    is_filtered = False
    filter_reason = None
    # Note that the value 'nucleotide_type' in barcodes.json may be empty.
    # I assume empty nucleotide_type is DNA.
    my_nucleotide_type = barcode_dict.get('nucleotide_type', '').upper()
    if my_nucleotide_type not in ['DNA', '']: 
        is_filtered = True
        filter_reason = 'Nucleotide type is not DNA.'
        return is_filtered, filter_reason
    if barcode_dict['read_count'] < BCFILE_MIN_READS:
        is_filtered = True
        filter_reason = 'read counts < minimum read counts %d' %BCFILE_MIN_READS
        return is_filtered, filter_reason
    return is_filtered, filter_reason

def get_configurations(barcoded_run, configured_run, start_mode, multisample):
    process_status = {'bams_filtered_out': [], 'bams_will_be_processed': [], 'bams_processed': []}
    configurations = {}
    if configured_run:
        printtime("Run is using configurations")
        for element in STARTPLUGIN_JSON['pluginconfig']['barcodes']:
            configuration_name = element['json']['pluginconfig'].get('meta',{}).get('configuration_name','')
            if configuration_name not in configurations:
                new_configuration = {'json': copy.deepcopy(element['json']), 'error': [], 'warning': [], 'bams': []}
                new_configuration['json'] ['plan'] = copy.deepcopy(STARTPLUGIN_JSON['plan'])
                new_configuration['json'] ['expmeta'] = copy.deepcopy(STARTPLUGIN_JSON['expmeta'])
                new_configuration['json'] ['runinfo'] = copy.deepcopy(STARTPLUGIN_JSON['runinfo'])
                configurations[configuration_name] = new_configuration
    else:
        printtime("Run is not using configurations")
        configuration_name = STARTPLUGIN_JSON['pluginconfig'].get('meta',{}).get('configuration_name','')
        configurations[configuration_name] = {'json': copy.deepcopy(STARTPLUGIN_JSON), 'error': [], 'warning': [], 'bams': []}
        
    if barcoded_run:
        printtime('Run is using barcodes')
        if configured_run:
            for element in STARTPLUGIN_JSON['pluginconfig']['barcodes']:
                configuration_name = element['json']['pluginconfig'].get('meta',{}).get('configuration_name','')                
                bam_basename = os.path.basename(element['bam'])
                
                # I'll try two different approaches to identiofy the barcode from the bam file name.
                # 1) Assume bam basename = (barcode)_rawlib.bam
                # 2) Search the bam file from all bam files in barcodes.json
                barcode_found = False
                # Approach 1)
                if bam_basename.endswith('_rawlib.bam'):
                    barcode = bam_basename[:-len('_rawlib.bam')]
                    try:
                        barcode_dict = BARCODES_JSON[barcode]
                        barcode_found = barcode_dict['bam_file'] == bam_basename
                    except KeyError:
                        pass
                # Approach 2)
                if not barcode_found:
                    for barcode, barcode_dict in BARCODES_JSON.iteritems():
                        if barcode_dict['bam_file'] == bam_basename:
                            barcode_found = True
                            break

                if not barcode_found:
                    configurations[configuration_name]['error'].append('Unknown bam file in the plugin config: %s' %bam_basename)
                    continue

                is_filtered, filter_reason = filter_barcode(barcode_dict)
                if is_filtered:
                    configurations[configuration_name]['warning'].append('Skip the barcode %s: %s' %(barcode, filter_reason))                                        
                    process_status['bams_filtered_out'].append(barcode)
                else:
                    bam_dict = {'name': barcode, 'barcode_index': barcode_dict['barcode_index'], 'sample': barcode_dict['sample'], 'file': barcode_dict['bam_filepath'], 'status': 'queued', 'error': [], 'warning': []}
                    configurations[configuration_name]['bams'].append(bam_dict)
                    process_status['bams_will_be_processed'].append(barcode)

        else:
            configuration_name = STARTPLUGIN_JSON['pluginconfig'].get('meta',{}).get('configuration_name','')
            for barcode, barcode_dict in BARCODES_JSON.iteritems():
                is_filtered, filter_reason = filter_barcode(barcode_dict)
                if is_filtered:
                    configurations[configuration_name]['warning'].append('Skip the barcode %s: %s' %(barcode, filter_reason))                    
                    process_status['bams_filtered_out'].append(barcode)
                else:
                    bam_dict = {'name': barcode, 'barcode_index': barcode_dict['barcode_index'], 'sample': barcode_dict['sample'], 'file': barcode_dict['bam_filepath'], 'status': 'queued', 'error': [], 'warning': []}
                    configurations[configuration_name]['bams'].append(bam_dict)
                    process_status['bams_will_be_processed'].append(barcode)
    else:
        printtime('Run is not using barcodes')
        if configured_run:
            configuration_name = STARTPLUGIN_JSON['pluginconfig']['barcodes'][0]['json']['pluginconfig'].get('meta',{}).get('configuration_name','')
        else:
            configuration_name = STARTPLUGIN_JSON['pluginconfig'].get('meta',{}).get('configuration_name','')
        is_filtered, filter_reason = filter_barcode(BARCODES_JSON[NONBARCODED])
        if is_filtered:
            configurations[configuration_name]['warning'].append('Skip the bam file %s: %s' %(BARCODES_JSON[NONBARCODED]['bam_filepath'], filter_reason))
            process_status['bams_filtered_out'].append(NONBARCODED)
        else:
            bam_dict = {'name': NONBARCODED, 'barcode_index': 0, 'sample': BARCODES_JSON[NONBARCODED]['sample'], 'file': BARCODES_JSON[NONBARCODED]['bam_filepath'], 'status': 'queued', 'error': [], 'warning': []}
            configurations[configuration_name]['bams'].append(bam_dict)
            process_status['bams_will_be_processed'].append(NONBARCODED)

    # Initial status of the configurations
    printtime('')
    for configuration_name, configuration in configurations.iteritems():
        configuration['name'] = configuration_name
        configuration['configured_run'] = configured_run
        configuration['barcoded_run'] = barcoded_run
        configuration['multisample'] = multisample
        configuration['start_mode'] = start_mode
        
        # Sort by barcode_index
        argsort_barcode_idx = sorted(range(len(configuration['bams'])), key = lambda bam_idx : configuration['bams'][bam_idx]['barcode_index'])
        configuration['bams'] = [configuration['bams'][idx] for idx in argsort_barcode_idx]
        printtime('Initial status of the configuration %s: ' %configuration_name)
        if not configuration['bams']:
            configuration['warning'].append('No valid bam file is associated with the configuration %s.' %configuration_name)
        else:
            for bam in configuration['bams']:                
                printtime('  %s: %s' %(bam['name'], bam['file']))
        for warning_msg in configuration['warning']:
            printtime('  WARNING: %s' % warning_msg)
        for error_msg in configuration['error']:
            printtime('  ERROR: %s' % error_msg)                
    printtime('')

    return configurations, process_status

def is_need_realignment(bam, options, desirable_tmap_args, planned_tmap_args):
    desirable_tmap_args = cleanup_cmd(desirable_tmap_args)
    planned_tmap_args = cleanup_cmd(planned_tmap_args)
    is_same_reference = BARCODES_JSON[bam['name']]['reference'] == options.serve_option('reference_genome_name', bam['name'])
    if not is_same_reference:
        # I want to realign the bam because the reference genome is different.
        printtime('Detected the change of the reference genome. Realign %s.' %(bam['file']))       
        return True
    if ' --bed-file ' in planned_tmap_args and BARCODES_JSON[bam['name']]['target_region_filepath'] != options.serve_option('targets_bed_unmerged', bam['name']):
        # I want to realign the bam because the tmap needs the target bed file and it is changed.
        printtime('Detected the change of the target region used in tmap. Realign %s' %(bam['file']))
        return True

    if desirable_tmap_args == '':
        # I didn't specify the desirable tmap args. No need to realign.
        return False

    if planned_tmap_args == '':
        # TS-15287 I realign the bam file anyway if I can't find the tmaparg in the run plan.
        printtime('Planned tmap args not found. Realign %s' %(bam['file']))
        return True
    
    # More clean-up
    planned_tmap_args = planned_tmap_args.replace(' ... ', ' ')
    planned_tmap_args = planned_tmap_args.replace(' --bed-file ', ' --bed-file %s ' %BARCODES_JSON[bam['name']]['target_region_filepath'])
    desirable_tmap_args = desirable_tmap_args.replace(' ... ', ' ')
    desirable_tmap_args = desirable_tmap_args.replace(' --bed-file ', ' --bed-file %s ' %options.serve_option('targets_bed_unmerged', bam['name']))
    planned_tmap_args_dict = cmd_args_to_dict(planned_tmap_args)
    desirable_tmap_args_dict = cmd_args_to_dict(desirable_tmap_args)
    
    # -q may be specify in the run plan but it doesn't affect the alignment.
    ignore_options = ['-q', '--reads-queue-size']
    for key in ignore_options:
        planned_tmap_args_dict.pop(key, None)
        desirable_tmap_args_dict.pop(key, None)
    
    #TODO(czb): Handle the long/short args ambiguity.
    need_realn = planned_tmap_args_dict != desirable_tmap_args_dict
    return need_realn

def process_reference(configuration, bam, tmap_server_key):
    if bam['status'] == 'error':
        # I won't process an erroneous bam.
        return
    with open(os.path.join(ANALYSIS_DIR, 'ion_params_00.json')) as f_ion_param_00_json:
        ion_param_00_json = json.load(f_ion_param_00_json)
    # Make symlink
    for key in ['reference_genome_fasta', 'reference_genome_fai']:
        source_path = configuration['options'].serve_option(key, bam['name'])
        local_path = os.path.join(TSP_FILEPATH_PLUGIN_DIR, os.path.basename(source_path))
        if not os.path.exists(local_path):
            os.symlink(source_path, local_path)

    # planned_tmap_args is the tmap args used in the plan (i.e., basically the cmd args for rawlib.bam).
    planned_tmap_args = ion_param_00_json.get('experimentAnalysisSettings', {}).get('alignmentargs', '')
    desirable_tmap_args = configuration['json']['pluginconfig'].get('meta',{}).get('tmapargs','')

    if is_need_realignment(bam, configuration['options'], desirable_tmap_args, planned_tmap_args):
        printtime('Planned alignemnt does not match the desirable alignment. Realign %s' %(bam['file']))
        assert(bam['file'].endswith('.bam'))
        realigned_bam_basename = '%s.realigned.bam' %os.path.basename(bam['file'])[:-4]
        realigned_bam_path = os.path.join(TSP_FILEPATH_PLUGIN_DIR, realigned_bam_basename)
        tmap_cmd = get_realign_cmd(bam, realigned_bam_path, planned_tmap_args, desirable_tmap_args, configuration['options'], tmap_server_key)
        if tmap_cmd == '':
            bam['status'] = 'error'
            bam['error'].append('Fail to realign the bam')
            return
        success = run_tmap(tmap_cmd, realigned_bam_path)
        if success:
            # Now Variant Caller Plugin is dealing with the realigned bam.
            bam['file'] = realigned_bam_path
        else:
            bam['status'] = 'error' 
            bam['error'].append('Fail to realign the bam')
    else:
        printtime("No need to realign the bam file %s" %bam['file'])

def make_directories(vc_pipeline_directory, configuration):
    if not os.path.exists(vc_pipeline_directory):
        os.makedirs(vc_pipeline_directory)
        
    for bam in configuration['bams']:
        if configuration['barcoded_run']:
            results_directory = os.path.join(TSP_FILEPATH_PLUGIN_DIR, bam['name'])
        else:
            results_directory = TSP_FILEPATH_PLUGIN_DIR
        if not os.path.exists(results_directory):
            os.makedirs(results_directory)
        bam['results_directory'] = results_directory

def get_untrimmed_bams(bams):
    untrimmed_bams_list = []
    for bam in bams:
        basename_input_bam = os.path.basename(bam['file'])
        untrimmed_bam = os.path.join(bam['results_directory'], basename_input_bam)
        bam['untrimmed_bam'] = untrimmed_bam
        if os.path.realpath(bam['file']) != os.path.realpath(untrimmed_bam):
            os.symlink(bam['file'], untrimmed_bam)
            os.symlink(bam['file'] + '.bai', untrimmed_bam + '.bai')
        untrimmed_bams_list.append(untrimmed_bam)
    return ','.join(untrimmed_bams_list)

def variant_caller_pipeline(configuration, queued_bams):
    # Assumption: has passed is_multisample_ok
    configuration_name = configuration['name']
    barcoded_run = configuration['barcoded_run']
    multisample = configuration['multisample']
    barcode = queued_bams[0]['name']
    # In TS 5.4 and earlier, the only case that we have multiple bams here is  multisample
    assert(len(queued_bams) == 1 or multisample)

    if not barcoded_run:
        vc_pipeline_directory = TSP_FILEPATH_PLUGIN_DIR
    elif multisample:
        vc_pipeline_directory = os.path.join(TSP_FILEPATH_PLUGIN_DIR, configuration_name)
    else:
        vc_pipeline_directory = os.path.join(TSP_FILEPATH_PLUGIN_DIR, barcode)

    make_directories(vc_pipeline_directory, configuration)
    for bam in queued_bams:
        bam['vc_pipeline_directory'] = vc_pipeline_directory
        
    # symlink parameter json
    parameter_path = configuration['options'].serve_option('parameters_file')                                   
    local_param_path_list = [os.path.join(bam['results_directory'], os.path.basename(parameter_path)) for bam in queued_bams]
    local_param_path_list.append(os.path.join(vc_pipeline_directory, os.path.basename(parameter_path)))
    for local_param_path in local_param_path_list:
        if not os.path.exists(local_param_path):
            os.symlink(parameter_path, local_param_path)
            
    # Set post_processed_bam
    # I output post processed bam if trim_reads or tagseq
    is_output_post_processed_bam = configuration['options'].serve_option('trim_reads', barcode) or configuration['options'].serve_option('has_umt', barcode)
    if is_output_post_processed_bam:
        for bam in queued_bams:
            if multisample:
                #TODO(CZB): Can multisample_processed.bam be downloaded?
                post_processed_bam = os.path.join(vc_pipeline_directory, 'multisample_processed.bam')
            else:
                assert(bam['file'].endswith('.bam'))
                post_processed_bam_basename = os.path.basename(bam['file'][:-4] + '_processed.bam')
                post_processed_bam = os.path.join(vc_pipeline_directory, post_processed_bam_basename)        
            bam['post_processed_bam'] = post_processed_bam
    
    # Bam files actually inputed in variant caller pipeline 
    untrimmed_bams = get_untrimmed_bams(queued_bams)

    # Prepare target regions
    prepare_target_regions(configuration['options'], queued_bams)

    # Prepare hotspots
    prepare_hotspots(configuration['options'], queued_bams)

    # Prepare sse bed
    prepare_sse_mask(configuration['options'], queued_bams)

    # Call variant_caller_pipeline.py
    variantcaller_command        = '%s/bin/variant_caller_pipeline.py' % DIRNAME
    variantcaller_command   +=     '  --input-bam "%s"' % untrimmed_bams
    
    if configuration['options'].serve_option('has_umt', barcode):       
        variantcaller_command   += '  --run-consensus on'
        # I did not check has_target here. I will let TVC raise error if targets_bed_unmerged is empty.
        # Note that I don't want to trim ampliseq primer in tagseq because of super-amplicon.
        # Thus I use the unmerged bed file as the region bed.        
        variantcaller_command   += '  --region-bed "%s"' % configuration['options'].serve_option('targets_bed_unmerged', barcode)
        # TS-17032 Disable AmpliSeq primer trimming for AMPS HD
        '''
        # Trim AmpliSeq Primer in AmpliSeq HD runs
        if configuration['options'].serve_option('library_type', barcode) == 'ampliseq_hd':
            variantcaller_command   += '  --primer-trim-bed "%s"' % configuration['options'].serve_option('targets_bed_unmerged', barcode)
        '''
    else:
        if configuration['options'].serve_option('has_targets', barcode):
            variantcaller_command   += '  --region-bed "%s"' % configuration['options'].serve_option('targets_bed_merged', barcode)        
            if configuration['options'].serve_option('trim_reads', barcode): 
                variantcaller_command   += '  --primer-trim-bed "%s"' % configuration['options'].serve_option('targets_bed_unmerged', barcode)
        variantcaller_command       += '  --generate-gvcf on'

    if is_output_post_processed_bam:
        variantcaller_command   += '  --postprocessed-bam "%s"' % post_processed_bam

    variantcaller_command       += '  --reference-fasta "%s"' % configuration['options'].serve_option('reference_genome_fasta', barcode)
    variantcaller_command       += '  --output-dir "%s"' % vc_pipeline_directory
    variantcaller_command       += '  --parameters-file "%s"' % configuration['options'].serve_option('parameters_file')
    variantcaller_command       += '  --bin-dir "%s/bin"' % DIRNAME # XXX Remove me and replace me with proper paths
    variantcaller_command       += '  --error-motifs-dir "%s"' % os.path.join(DIRNAME, 'share/TVC/sse')
    if configuration['options'].serve_option('error_motifs') != '':
        variantcaller_command       += '  --error-motifs "%s"' % configuration['options'].serve_option('error_motifs')
    if configuration['options'].serve_option('hotspots_vcf', barcode) != '':
        variantcaller_command   += '  --hotspot-vcf "%s"' %configuration['options'].serve_option('hotspots_vcf', barcode) 
    if configuration['options'].serve_option('sse_vcf', barcode) != '':
        variantcaller_command   += '  --sse-vcf "%s"' %configuration['options'].serve_option('sse_vcf', barcode)

    if PLUGIN_DEV_SKIP_VARIANT_CALLING:
        printtime('Skipping calling variants on mapped reads.')
        printtime('Command: %s' %variantcaller_command)
    else:
        run_command(variantcaller_command, 'Execute variant caller script')


def split_results(options, bams):
    vc_pipeline_directory = bams[0]['vc_pipeline_directory']
    multisample_processed_bam = bams[0].get('post_processed_bam', None)
    if len(bams) == 1:
        run_command("cp " + os.path.join(vc_pipeline_directory,'small_variants.vcf') + " " + os.path.join(vc_pipeline_directory,'small_variants_1.vcf'), "Copy small_variants.vcf")
        run_command("cp " + os.path.join(vc_pipeline_directory,'small_variants_filtered.vcf') + " " + os.path.join(vc_pipeline_directory,'small_variants_filtered_1.vcf'), "Copy small_variants_filtered.vcf")
        run_command("cp " + os.path.join(vc_pipeline_directory, BASENAME_VARIANTS_VCF) + " " + os.path.join(vc_pipeline_directory, BASENAME_VARIANTS_VCF.replace('.vcf', '_1.vcf')), "Copy %s" %BASENAME_VARIANTS_VCF)
        run_command("cp " + os.path.join(vc_pipeline_directory, BASENAME_GENOME_VCF) + " " + os.path.join(vc_pipeline_directory, BASENAME_GENOME_VCF.replace('.genome.vcf', '_1.genome.vcf')), "Copy %s" %BASENAME_GENOME_VCF)
    else:
        cmd = '%s split_vcf' %TVCUTILS
        cmd += ' --input-vcf ' + os.path.join(vc_pipeline_directory,'small_variants.vcf')
        cmd += ' --out-dir ' + vc_pipeline_directory
        run_command(cmd, 'Split small_variants.vcf')
        cmd = '%s split_vcf' %TVCUTILS
        cmd += ' --input-vcf ' + os.path.join(vc_pipeline_directory,'small_variants_filtered.vcf')
        cmd += ' --out-dir ' + vc_pipeline_directory
        run_command(cmd, 'Split small_variants_filtered.vcf')
        cmd = '%s split_vcf' %TVCUTILS
        cmd += ' --input-vcf ' + os.path.join(vc_pipeline_directory, BASENAME_VARIANTS_VCF)
        cmd += ' --out-dir ' + vc_pipeline_directory
        run_command(cmd, 'Split %s'%BASENAME_VARIANTS_VCF)
        cmd = '%s split_vcf'%TVCUTILS
        cmd += ' --input-vcf ' + os.path.join(vc_pipeline_directory, BASENAME_GENOME_VCF)
        cmd += ' --out-dir ' + vc_pipeline_directory
        run_command(cmd, 'Split %s'%BASENAME_GENOME_VCF)
        
    for dataset_num, bam in enumerate(bams):
        if options.is_barcoded_run():
            basename_variants_vcf  = BASENAME_VARIANTS_VCF.replace('.vcf', '_%s.vcf' % bam['name'])
            basename_genome_vcf    = BASENAME_GENOME_VCF.replace('.genome.vcf', '_%s.genome.vcf' % bam['name'])
        else:
            basename_variants_vcf  = BASENAME_VARIANTS_VCF
            basename_genome_vcf    = BASENAME_GENOME_VCF
        results_directory = bam['results_directory']
        if not os.path.exists(results_directory):
            os.makedirs(results_directory)
        if os.path.exists(os.path.join(vc_pipeline_directory,"effective_regions.bed")):
            if not os.path.lexists(os.path.join(results_directory,"effective_regions.bed")):
                os.symlink(os.path.join(vc_pipeline_directory,'effective_regions.bed'), os.path.join(results_directory,"effective_regions.bed"))
        if not os.path.lexists(os.path.join(results_directory,"small_variants.vcf")):
            os.symlink(os.path.join(vc_pipeline_directory,'small_variants_' + str(dataset_num + 1) + '.vcf'), os.path.join(results_directory,"small_variants.vcf"))
        if not os.path.lexists(os.path.join(results_directory,"small_variants_filtered.vcf")):
            os.symlink(os.path.join(vc_pipeline_directory,'small_variants_filtered_' + str(dataset_num + 1) + '.vcf'), os.path.join(results_directory,"small_variants_filtered.vcf"))
        if not os.path.lexists(os.path.join(results_directory,BASENAME_VARIANTS_VCF)):
            os.symlink(os.path.join(vc_pipeline_directory,BASENAME_VARIANTS_VCF.replace('.vcf', '_%s.vcf' % str(dataset_num + 1))), os.path.join(results_directory, BASENAME_VARIANTS_VCF))

        # In the block below there are multiple problems, incl. unassinged variables
        # Giving unassinged vaiables a dummy name
        processed_bam = 'dummy.bam'
        if multisample_processed_bam is not None:
            read_group_id = ''
            proc = subprocess.Popen(['samtools', 'view', '-H', bam['file']], stdout=subprocess.PIPE)
            lines = proc.stdout.readlines()
            filename = os.path.join(results_directory, 'read_id.txt')
            fout = open(filename, 'w')
            for line in lines:
                if line.startswith('@RG\tID:'):
                    read_group_id = line[7:].split('\t')[0]
                    fout.write(read_group_id + '\n')
            fout.close()
            run_command("samtools view -bhR " + filename + " " + multisample_processed_bam + " > " + processed_bam, "Split multisample processed bam")
            run_command("samtools index " + processed_bam, "Index processed bam")
        else:
            processed_bam = bam['file']
        
        cmd = "samtools depth "
        if options.serve_option('has_targets', bam['name']):
            cmd += "-b '" + options.serve_option('targets_bed_unmerged', bam['name']) + "' "
        cmd += processed_bam + " | "
        cmd += "%s unify_vcf " %TVCUTILS
        cmd += "  --novel-tvc-vcf %s" %os.path.join(vc_pipeline_directory, BASENAME_VARIANTS_VCF.replace('.vcf', '_%s.vcf' % str(dataset_num + 1))) 
        cmd += "  --output-vcf %s.gz" %os.path.join(results_directory,basename_variants_vcf)
        cmd += "  --reference-fasta '%s'" %options.serve_option('reference_genome_fasta', bam['name'])
        if options.serve_option('has_targets', bam['name']):
            cmd += "  --target-file '%s'" %options.serve_option('targets_bed_unmerged', bam['name'])
        if options.serve_option('hotspots_vcf', bam['name']):
            cmd += "  --hotspot-annotation-vcf '%s'" %options.serve_option('hotspots_vcf', bam['name'])
        cmd += "  --input-depth stdin "
        # TODO: Need to deal with --gen-min-coverage in tvc args
        gen_min_coverage = options.serve_option('parameters', bam['name']).get('freebayes', {}).get('gen_min_coverage', 6)
        cmd += '  --min-depth %s' %str(gen_min_coverage) 
        run_command(cmd, "Create genome vcf")
        run_command("gzip -dcf " + os.path.join(results_directory,basename_variants_vcf) + ".gz > " + os.path.join(results_directory,basename_variants_vcf), "unzip vcf")
        run_command("gzip -dcf " + os.path.join(results_directory,basename_genome_vcf) + ".gz > " + os.path.join(results_directory,basename_genome_vcf), "unzip genome vcf")

        if not os.path.lexists(os.path.join(results_directory,BASENAME_GENOME_VCF)):
            os.symlink(os.path.join(results_directory,basename_genome_vcf),
                       os.path.join(results_directory,BASENAME_GENOME_VCF))

        package_vcf(os.path.join(results_directory,BASENAME_VARIANTS_VCF))
        package_vcf(os.path.join(results_directory,BASENAME_GENOME_VCF))
        package_vcf(os.path.join(results_directory,basename_variants_vcf))
        package_vcf(os.path.join(results_directory,basename_genome_vcf))

def generate_hotspot_allele_cov(options, bam):
    if options.serve_option('has_hotspots', bam['name']):
        allelecount_command = 'samtools mpileup -BQ0 -d1000000'
        allelecount_command += ' -f "%s"' % options.serve_option('reference_genome_fasta', bam['name'])
        allelecount_command += ' -l %s' %options.serve_option('hotspots_bed_merged', bam['name'])
        if options.serve_option('trim_reads', bam['name']):
            allelecount_command += ' ' + bam['post_processed_bam']
        else:
            allelecount_command += ' ' + bam['untrimmed_bam']
        allelecount_command += ' | %s/scripts/allele_count_mpileup_stdin.py' % DIRNAME
        allelecount_command += ' > ' + os.path.join(bam['results_directory'],'allele_counts.txt')
        if PLUGIN_DEV_SKIP_VARIANT_CALLING:
            printtime('Skipping base pileup for hotspot alleles.')
            printtime('Command: %s' %allelecount_command)
        else:
            run_command(allelecount_command,'Base pileup for hotspot alleles')

        allelecount2_command = '%s/scripts/print_allele_counts.py' % DIRNAME
        allelecount2_command += ' ' + os.path.join(bam['results_directory'],'allele_counts.txt')
        allelecount2_command += ' ' + os.path.join(bam['results_directory'],BASENAME_HOTSPOTS_XLS)
        allelecount2_command += ' "%s"' % options.serve_option('hotspots_bed_unmerged_leftalign', bam['name'])
        allelecount2_command += ' "%s"' % options.serve_option('hotspots_bed_unmerged', bam['name'])
        if PLUGIN_DEV_SKIP_VARIANT_CALLING:
            printtime('Skipping generate hotspots allele coverage.')
            printtime('Command: %s' %allelecount2_command)
        else:              
            run_command(allelecount2_command,'Generate hotspots allele coverage')
        

def generate_variant_tables(configuration, bam):
    tvc_args = configuration['json']['pluginconfig']['meta'].get('tvcargs','')
    table_command        = '%s/scripts/generate_variant_tables.py' % DIRNAME
    if tvc_args.find("--suppress-no-calls off") != -1: 
        table_command   += '  --suppress-no-calls off'
    else: 
        table_command   += '  --suppress-no-calls on'
    table_command       += '  --input-vcf %s'       % os.path.join(bam['results_directory'], BASENAME_VARIANTS_VCF)
    if configuration['options'].serve_option('has_targets', bam['name']):
        table_command   += '  --region-bed "%s"'    % configuration['options'].serve_option('targets_bed_unmerged', bam['name'])
    if configuration['options'].serve_option('has_hotspots', bam['name']):
        table_command   += '  --hotspots'
    table_command       += '  --output-xls %s'      % os.path.join(bam['results_directory'], BASENAME_VARIANTS_XLS)
    table_command       += '  --alleles2-xls %s'    % os.path.join(bam['results_directory'], BASENAME_ALLELES_XLS)
    table_command       += '  --summary-json %s'    % os.path.join(bam['results_directory'], 'variant_summary.json')
    table_command       += '  --scatter-png %s'     % os.path.join(bam['results_directory'], 'scatter.png')
    if configuration['barcoded_run']:
        table_command   += '  --barcode %s'  % bam['name']
        table_command   += '  --concatenated-xls "%s/%s.xls"' % (TSP_FILEPATH_PLUGIN_DIR, configuration['options'].serve_option('run_name', bam['name']))
    table_command       += '  --run-name "%s"'  % configuration['options'].serve_option('run_name', bam['name'])
    table_command       += '  --library-type "%s"'  % configuration['options'].serve_option('library_type', bam['name'])
    if PLUGIN_DEV_SKIP_VARIANT_CALLING:
        printtime('Skipping generate xls tables and statistics from final vcf.')
        printtime('Command: %s' %table_command)
    else:    
        run_command(table_command,'Generate xls tables and statistics from final vcf')

def transfer_variants_to_sqlite(results_directory):
    subprocess.call('rm -f %s'     % os.path.join(results_directory,'alleles.db'), shell=True)
    (fin,unique_filename) = tempfile.mkstemp()
    sqllite_command        = 'python %s/scripts/csv2sqlite.py' % DIRNAME
    sqllite_command       += '  %s'     % os.path.join(results_directory,BASENAME_ALLELES_XLS)
    sqllite_command       += '  %s'     % unique_filename
    sqllite_command       += '  variants'
    run_command(sqllite_command,'Transfer variants to sqllite database')
    #copy sqllitedatabase to 
    copysql_command  = 'cp  %s  ' % unique_filename
    copysql_command += '  %s' %  os.path.join(results_directory,'alleles.db')
    run_command(copysql_command,'copy sqlite database to distination ')
    subprocess.call('rm -f %s'     % unique_filename, shell=True)
    os.chmod(os.path.join(results_directory,'alleles.db'), 0777)

def setup_webpage_support(results_directory):
    # Create symlinks to js/css folders and php scripts # static data
    subprocess.call('ln -sf "%s/slickgrid" "%s"' % (DIRNAME,results_directory),shell=True)
    subprocess.call('cp -rf %s/copytoreport/* "%s"' % (DIRNAME,results_directory),shell=True)
    subprocess.call('ln -sf %s/scripts/*.php3 "%s"' % (DIRNAME,results_directory),shell=True)
    
def load_render_context(render_context, bam, options):
    if options.is_barcoded_run():
        render_context['results_url'] += '/' + bam['name']

    with open(os.path.join(bam['results_directory'],'variant_summary.json'), 'r') as summary_in:
        render_context['summary'] = json.load(summary_in)

    if options.serve_option('has_umt', bam['name']):
        df = pd.read_csv(os.path.join(bam['results_directory'],'consensus_metrics.txt'), sep = ':', names=['metric','value'], index_col='metric')
        render_context['summary']['median_depth'] =  int(float(df.get_value('Median read coverage','value')))
        render_context['summary']['median_num_fam3'] = int(float(df.get_value('Median molecular coverage','value')))
        render_context['summary']['fm3_pass80'] =  ("%s - %s" % (df.get_value('Median LOD percent','value'), df.get_value('80th percentile LOD percent','value')))
    else:
        render_context['summary']['median_depth'] = "NA"
        render_context['summary']['median_num_fam3'] = "NA"
        render_context['summary']['fm3_pass80'] = "NA" 

    if options.serve_option('has_targets', bam['name']):
        render_context['targets_bed_link'] = os.path.basename(options.serve_option('targets_bed_unmerged', bam['name']))

    if options.serve_option('has_hotspots', bam['name']):
        render_context['hotspots_bed_link'] = os.path.basename(options.serve_option('hotspots_bed_unmerged_local', bam['name']))
        render_context['summary']['has_hotspots'] = True
    else:
        render_context['summary']['has_hotspots'] = False

    if options.serve_option('has_targets', bam['name']) and options.serve_option('trim_reads', bam['name']):
        render_context['effective_regions_bed_link'] = 'effective_regions.bed'

    if options.is_barcoded_run():
        render_context['barcode'] = bam['name']
        
def create_symlinks(options, bam, render_context):
    results_directory = bam['results_directory']
    if options.is_barcoded_run():
        if not os.path.lexists(os.path.join(results_directory,render_context['variants_vcf_gz_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_VARIANTS_VCF+'.gz'),
                       os.path.join(results_directory,render_context['variants_vcf_gz_link']))
        if not os.path.lexists(os.path.join(results_directory,render_context['variants_tbi_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_VARIANTS_VCF+'.gz.tbi'),
                       os.path.join(results_directory,render_context['variants_tbi_link']))
        if not os.path.lexists(os.path.join(results_directory,render_context['genome_vcf_gz_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_GENOME_VCF+'.gz'),
                       os.path.join(results_directory,render_context['genome_vcf_gz_link']))
        if not os.path.lexists(os.path.join(results_directory,render_context['genome_tbi_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_GENOME_VCF+'.gz.tbi'),
                       os.path.join(results_directory,render_context['genome_tbi_link']))
        if not os.path.lexists(os.path.join(results_directory,render_context['variants_xls_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_VARIANTS_XLS),
                       os.path.join(results_directory,render_context['variants_xls_link']))
        if not os.path.lexists(os.path.join(results_directory,render_context['alleles_xls_link'])):
            os.symlink(os.path.join(results_directory,BASENAME_ALLELES_XLS),
                       os.path.join(results_directory,render_context['alleles_xls_link']))
        if options.serve_option('has_hotspots', bam['name']):
            if not os.path.lexists(os.path.join(results_directory,render_context['hotspots_xls_link'])):
                os.symlink(os.path.join(results_directory,BASENAME_HOTSPOTS_XLS),
                           os.path.join(results_directory,render_context['hotspots_xls_link']))

def render_webpages(results_directory, render_context):
    with open(os.path.join(results_directory, HTML_RESULTS), 'w') as out:
        out.write(render_to_string('report_details.html', render_context))

    with open(os.path.join(results_directory, HTML_BLOCK), 'w') as out:
        out.write(render_to_string('block_details.html', render_context))
    
    with open(os.path.join(results_directory, 'deprecated.htm'), 'w') as out: 
        out.write(render_to_string('report_deprecated.html', render_context))

def generate_variant_allele_cov(options, bam, render_context):
    basename_variants_bed = BASENAME_VARIANTS_VCF.replace('.vcf', '.bed')
    basename_allele_counts = BASENAME_VARIANTS_VCF.replace('.vcf', '_allele_counts.txt')
    tvcutils_command = "%s prepare_hotspots" %TVCUTILS
    tvcutils_command += ' --reference "%s"' % options.serve_option('reference_genome_fasta', bam['name'])
    tvcutils_command += ' --input-vcf "%s"' % os.path.join(bam['results_directory'], BASENAME_VARIANTS_VCF)
    tvcutils_command += ' --output-bed "%s"' % os.path.join(bam['results_directory'], basename_variants_bed)
    run_command(tvcutils_command,'Write variants bed')
    allelecount_command = 'samtools mpileup -BQ0 -d1000000'
    allelecount_command += ' -f "%s"' % options.serve_option('reference_genome_fasta', bam['name'])
    allelecount_command += ' -l ' + os.path.join(bam['results_directory'], basename_variants_bed)
    if bam.get('post_processed_bam', None) is not None:
        allelecount_command += ' ' + bam['post_processed_bam']
    else:
        allelecount_command += ' ' + bam['untrimmed_bam']
    allelecount_command += ' | %s/scripts/allele_count_mpileup_stdin.py' % DIRNAME
    allelecount_command += ' > ' + os.path.join(bam['results_directory'], basename_allele_counts)
    if PLUGIN_DEV_SKIP_VARIANT_CALLING:
        printtime('Skipping base pileup for variant alleles.')
        printtime('Command: %s' %allelecount_command)
    else:
        run_command(allelecount_command,'Base pileup for variant alleles')
    allelecount2_command = '%s/scripts/print_variant_allele_counts.py' % DIRNAME
    allelecount2_command += ' ' + bam['name']
    allelecount2_command += " '" + render_context['summary']['sample_name'] + "'"
    allelecount2_command += ' ' + os.path.join(bam['results_directory'], BASENAME_VARIANTS_VCF)
    allelecount2_command += ' ' + os.path.join(bam['results_directory'], basename_allele_counts)
    allelecount2_command += ' ' + os.path.join(bam['results_directory'], BASENAME_VARIANT_COV_XLS)
    if PLUGIN_DEV_SKIP_VARIANT_CALLING:
        printtime('Skipping generate variant allele coverage.')
        printtime('Command: %s' %allelecount2_command)
    else:    
        run_command(allelecount2_command,'Generate variant allele coverage')

def generate_xml_template_for_igv(options, barcode_modifier, basename_variants_vcf, bam, render_context):
    processed_bam = bam.get('post_processed_bam', None)
    untrimmed_bam = bam['untrimmed_bam']
    
    # Create xml template required for adding IGV links
    fxml = open(os.path.join(bam['results_directory'],'igv_session.xml'), "w")
    fxml.write('<?xml version="1.0" encoding="UTF-8" standalone="no"?>\n')
    if options.serve_option('reference_genome_name', bam['name']) == 'hg19':
        fxml.write('<Global genome="%s" version="3">\n' % options.serve_option('reference_genome_name', bam['name']))
    else:    
        fxml.write('<Global genome="{plugin_url}/%s.fasta" version="3">\n' % (barcode_modifier + options.serve_option('reference_genome_name', bam['name'])))
    fxml.write('    <Resources>\n')
    fxml.write('        <Resource name="%s.gz" path="{plugin_url}/%s.gz"/>\n' % (basename_variants_vcf,basename_variants_vcf))
    if processed_bam is not None:
        fxml.write('        <Resource name="%s" path="{plugin_url}/%s"/>\n' % (os.path.basename(processed_bam),os.path.basename(processed_bam)))
    else:
        fxml.write('        <Resource name="%s" path="{plugin_url}/%s"/>\n' % (os.path.basename(untrimmed_bam),os.path.basename(untrimmed_bam)))
    if options.serve_option('has_targets', bam['name']):
        fxml.write('        <Resource name="%s" path="{plugin_url}/%s"/>\n' % (render_context['targets_bed_link'],barcode_modifier+render_context['targets_bed_link']))
    if options.serve_option('has_hotspots', bam['name']):
        fxml.write('        <Resource name="%s" path="{plugin_url}/%s"/>\n' % (render_context['hotspots_bed_link'],barcode_modifier+render_context['hotspots_bed_link']))
    if options.serve_option('has_targets', bam['name']) and options.serve_option('trim_reads', bam['name']):
        fxml.write('        <Resource name="%s" path="{plugin_url}/%s"/>\n' % (render_context['effective_regions_bed_link'],render_context['effective_regions_bed_link']))
    fxml.write('    </Resources>\n')
    fxml.write('    <Panel name="DataPanel" height="150">\n')
    fxml.write('        <Track displayMode="EXPANDED" id="{plugin_url}/%s.gz" name="Variant Calls" visible="true"/>\n' % basename_variants_vcf)
    if options.serve_option('has_targets', bam['name']):
        fxml.write('        <Track displayMode="COLLAPSED" id="{plugin_url}/%s" name="%s" visible="true"/>\n' % (barcode_modifier+render_context['targets_bed_link'], options.serve_option('targets_name', bam['name'])))
    if options.serve_option('has_hotspots', bam['name']):
        fxml.write('        <Track displayMode="COLLAPSED" id="{plugin_url}/%s" name="%s" visible="true"/>\n' % (barcode_modifier+render_context['hotspots_bed_link'], options.serve_option('hotspots_name', bam['name'])))
    if options.serve_option('has_targets', bam['name']) and options.serve_option('trim_reads', bam['name']):
        fxml.write('        <Track displayMode="COLLAPSED" id="{plugin_url}/%s" name="%s" visible="true"/>\n' % (render_context['effective_regions_bed_link'], options.serve_option('targets_name', bam['name']) + '_effective'))
    fxml.write('    </Panel>\n')
    fxml.write('    <Panel height="525">\n')
    if processed_bam is not None:
        fxml.write('        <Track displayMode="COLLAPSED" id="{plugin_url}/%s_coverage" name="Coverage" visible="true"/>\n' % os.path.basename(processed_bam))
        fxml.write('        <Track displayMode="EXPANDED" id="{plugin_url}/%s" name="Alignments" visible="true"/>\n' % os.path.basename(processed_bam))
    else:
        fxml.write('        <Track displayMode="COLLAPSED" id="{plugin_url}/%s_coverage" name="Coverage" visible="true"/>\n' % os.path.basename(untrimmed_bam))
        fxml.write('        <Track displayMode="EXPANDED" id="{plugin_url}/%s" name="Alignments" visible="true"/>\n' % os.path.basename(untrimmed_bam))
    fxml.write('    </Panel>\n')
    fxml.write('    <Panel name="FeaturePanel" height="75">\n')
    fxml.write('        <Track displayMode="COLLAPSED" id="Reference sequence" name="Reference sequence" visible="true"/>\n')
    fxml.write('    </Panel>\n')
    fxml.write('    <PanelLayout dividerFractions="0.20,0.75"/>\n')
    fxml.write('</Global>\n')
    fxml.close()

def add_output_files(bam, render_context):
    # List of generated files:
    if bam['name'] != NONBARCODED:
        add_output_file('variants_vcf_gz', bam['name']+'/'+render_context['variants_vcf_gz_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('variants_vcf_gz_tbi', bam['name']+'/'+render_context['variants_tbi_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('genome_vcf_gz', bam['name']+'/'+render_context['genome_vcf_gz_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('genome_vcf_gz_tbi', bam['name']+'/'+render_context['genome_tbi_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('alleles_xls', bam['name']+'/'+render_context['alleles_xls_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('mapped_bam', bam['name']+'/'+render_context['mapped_bam_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('mapped_bam_bai', bam['name']+'/'+render_context['mapped_bai_link'], bam['name'], render_context['summary']['sample_name'])
        if bam.get('post_processed_bam', None) is not None:
            add_output_file('processed_bam', bam['name']+'/'+render_context['processed_bam_link'], bam['name'], render_context['summary']['sample_name'])
            add_output_file('processed_bam_bai', bam['name']+'/'+render_context['processed_bai_link'], bam['name'], render_context['summary']['sample_name'])
        add_output_file('filtered_variants_vcf', bam['name']+'/small_variants_filtered.vcf', bam['name'], render_context['summary']['sample_name'])
    else:
        add_output_file('variants_vcf_gz', render_context['variants_vcf_gz_link'], sample=render_context['summary']['sample_name'])
        add_output_file('variants_vcf_gz_tbi', render_context['variants_tbi_link'], sample=render_context['summary']['sample_name'])
        add_output_file('genome_vcf_gz', render_context['genome_vcf_gz_link'], sample=render_context['summary']['sample_name'])
        add_output_file('genome_vcf_gz_tbi', render_context['genome_tbi_link'], sample=render_context['summary']['sample_name'])
        add_output_file('alleles_xls', render_context['alleles_xls_link'], sample=render_context['summary']['sample_name'])
        add_output_file('mapped_bam', render_context['mapped_bam_link'], sample=render_context['summary']['sample_name'])
        add_output_file('mapped_bam_bai', render_context['mapped_bai_link'], sample=render_context['summary']['sample_name'])
        if bam.get('post_processed_bam', None) is not None:
            add_output_file('processed_bam', render_context['processed_bam_link'], sample=render_context['summary']['sample_name'])
            add_output_file('processed_bam_bai', render_context['processed_bai_link'], sample=render_context['summary']['sample_name'])
        add_output_file('filtered_variants_vcf', 'small_variants_filtered.vcf', sample=render_context['summary']['sample_name'])

def process_results(configuration, bam):
    if configuration['barcoded_run']:
        barcode_modifier       = '../'
        basename_variants_vcf  = BASENAME_VARIANTS_VCF.replace('.vcf', '_%s.vcf' %bam['name']) 
        basename_genome_vcf    = BASENAME_GENOME_VCF.replace('.genome.vcf', '_%s.genome.vcf' %bam['name'])
        basename_variants_xls  = BASENAME_VARIANTS_XLS.replace('.xls', '_%s.xls' %bam['name'])
        basename_hotspots_xls  = BASENAME_HOTSPOTS_XLS.replace('.xls', '_%s.xls' %bam['name'])
        basename_alleles_xls   = BASENAME_ALLELES_XLS.replace('.xls', '_%s.xls' %bam['name'])
        basename_variant_cov_xls  = BASENAME_VARIANT_COV_XLS.replace('.xls', '_%s.xls' %bam['name'])
    else:
        barcode_modifier = ''
        basename_variants_vcf  = BASENAME_VARIANTS_VCF
        basename_genome_vcf    = BASENAME_GENOME_VCF
        basename_variants_xls  = BASENAME_VARIANTS_XLS
        basename_hotspots_xls  = BASENAME_HOTSPOTS_XLS
        basename_alleles_xls   = BASENAME_ALLELES_XLS
        basename_variant_cov_xls  = BASENAME_VARIANT_COV_XLS

    if not os.path.exists(bam['results_directory']):
        os.makedirs(bam['results_directory'])

    generate_hotspot_allele_cov(configuration['options'], bam)
    generate_variant_tables(configuration, bam)
    transfer_variants_to_sqlite(bam['results_directory'])
    setup_webpage_support(bam['results_directory'])
    # The url to the metal of the barcode
    barcode_metal_url = "../../../../../report/%s/metal/plugin_out/%s" %(STARTPLUGIN_JSON['runinfo']['pk'], os.path.basename(STARTPLUGIN_JSON['runinfo']['results_dir']))
    if bam['name'] != NONBARCODED:
        barcode_metal_url = '../%s/%s' %(barcode_metal_url, bam['name'])        
    render_context = {
        'options'               : configuration['options'].get_option_dict(bam['name']),
        'configuration_link'    : configuration['options'].serve_option('parameters_file'),
        'parameter_name'        : os.path.basename(configuration['options'].serve_option('parameters_file')),
        'mapped_bam_link'       : os.path.basename(bam['untrimmed_bam']),
        'mapped_bai_link'       : os.path.basename(bam['untrimmed_bam']) +'.bai',
        'variants_vcf_gz_link'  : basename_variants_vcf+'.gz',
        'variants_tbi_link'     : basename_variants_vcf+'.gz.tbi',
        'genome_vcf_gz_link'    : basename_genome_vcf+'.gz',
        'genome_tbi_link'       : basename_genome_vcf+'.gz.tbi',
        'variants_xls_link'     : basename_variants_xls,
        'alleles_xls_link'      : basename_alleles_xls,
        'hotspots_xls_link'     : basename_hotspots_xls,
        'variant_cov_xls_link'  : basename_variant_cov_xls,
        'results_url'           : TSP_URLPATH_PLUGIN_DIR,
        'startplugin_json'      : STARTPLUGIN_JSON,
        'barcode_metal_url'    : barcode_metal_url,
    }
    render_context['has_processed_bam'] = bam.get('post_processed_bam', None) is not None
    if render_context['has_processed_bam']:
        render_context['processed_bam_link'] = os.path.basename(bam.get('post_processed_bam'))
        render_context['processed_bai_link'] = render_context['processed_bam_link'] + '.bai'

    
    load_render_context(render_context, bam, configuration['options'])
    create_symlinks(configuration['options'], bam, render_context)
    subprocess.call('touch %s/%s.done' % (bam['results_directory'], basename_variants_vcf), shell=True)
    render_webpages(bam['results_directory'], render_context)

    if configuration['barcoded_run']:
        os.symlink(os.path.join(bam['results_directory'], BASENAME_VARIANT_COV_XLS),
                   os.path.join(bam['results_directory'], basename_variant_cov_xls))

    generate_variant_allele_cov(configuration['options'], bam, render_context)
    generate_xml_template_for_igv(configuration['options'], barcode_modifier, basename_variants_vcf, bam, render_context)
    add_output_files(bam, render_context)

    # For generating download link in the block html page.
    for key in ['variants_vcf_gz_link', 'variants_tbi_link', 'genome_vcf_gz_link', 'genome_tbi_link', 'alleles_xls_link']:
        if configuration['barcoded_run']:
            render_context['summary'][key] = '%s/%s' %(bam['name'], render_context[key])
        else:
            render_context['summary'][key] = render_context[key]
    render_context['summary']['barcode_details'] = os.path.join(bam['name'], HTML_RESULTS) if configuration['barcoded_run'] else HTML_RESULTS
    
    return render_context['summary']

def setup_results_json(barcoded_run):
    results_json = {
        'files'             : []
    }
    if barcoded_run:
        results_json['barcoded'] = 'true'
        results_json['barcodes'] = {}
    else:
        results_json['barcoded'] = 'false'
    return results_json

def write_parameters_file(options):        
    with open(options.serve_option('parameters_file'), 'w') as f_param:
        json.dump(options.serve_option('parameters'), f_param, indent = 4)
    add_output_file('parameters_json', os.path.basename(options.serve_option('parameters_file')))

def load_results_json(options, bam, results_json):
    try:
        with open(os.path.join(bam['vc_pipeline_directory'], "tvc_metrics.json"), 'r') as fin:
            metrics = json.load(fin, parse_float = str)
    except:
        metrics = {}
    barcode = bam['name']
    result_dict = {}
    result_dict['Aligned Reads'] = options.serve_option('run_name', barcode)
    result_dict['Library Type'] = options.serve_option('library_type', barcode)
    result_dict['Configuration'] = options.serve_option('parameters', barcode)['meta']['configuration']
    result_dict['Trim Reads'] = options.serve_option('trim_reads', barcode)
    result_dict['variants'] = bam['summary'].get('variants_total', {})
    result_dict['hotspots'] = bam['summary'].get('hotspots_total', {'variants': 0}) # In case there is no valid allele in the hotspots file.
    result_dict['deamination_metric'] = metrics.get('metrics', {}).get('deamination_metric', 0)
    
    if options.is_barcoded_run():
        if options.serve_option('has_targets', barcode):
            result_dict['targets_bed']  = options.serve_option('targets_bed_unmerged', barcode)
        if options.serve_option('has_hotspots', barcode):
            result_dict['hotspots_bed'] = options.serve_option('hotspots_bed_unmerged', barcode)
        results_json['barcodes'][barcode] = result_dict
    else:
        result_dict['Target Regions'] = options.serve_option('targets_name', barcode) if options.serve_option('has_targets', barcode) else 'Not using'
        result_dict['Target Loci'] = options.serve_option('hotspots_name', barcode) if options.serve_option('has_hotspots', barcode) else 'Not using'
        results_json = result_dict

def generate_download_files(run_name, bams_processed):
    printtime(' ')
    printtime('Task    : ' + 'Store per-barcode vcf files in a single zip file')
    zipfilename = '%s/%s.vcf.zip' % (TSP_FILEPATH_PLUGIN_DIR,run_name)
    for myfile in [('%s/%s/TSVC_variants_%s.vcf.gz' % (TSP_FILEPATH_PLUGIN_DIR,bam['name'],bam['name'])) for bam in bams_processed if bam['status'] == 'completed']:
        compress.make_zip(zipfilename, myfile, arcname=os.path.basename(myfile), use_sys_zip = False)
    for myfile in [('%s/%s/TSVC_variants_%s.vcf.gz.tbi' % (TSP_FILEPATH_PLUGIN_DIR,bam['name'],bam['name'])) for bam in bams_processed if bam['status'] == 'completed']:
        compress.make_zip(zipfilename, myfile, arcname=os.path.basename(myfile), use_sys_zip = False)
    printtime(' ')
    printtime(' ')
    printtime('Task    : ' + 'Store per-barcode xls files in a single zip file')
    zipfilename = '%s/%s.xls.zip' % (TSP_FILEPATH_PLUGIN_DIR,run_name)
    for myfile in [('%s/%s/alleles_%s.xls' % (TSP_FILEPATH_PLUGIN_DIR,bam['name'],bam['name'])) for bam in bams_processed if bam['status'] == 'completed']:
        compress.make_zip(zipfilename, myfile, arcname=os.path.basename(myfile), use_sys_zip = False)
    printtime(' ')
    printtime('Task    : ' + 'Store per-barcode cov files in a single zip file')
    combinedfilename = '%s/%s.cov.xls' % (TSP_FILEPATH_PLUGIN_DIR,run_name)
    for myfile in [('%s/%s/variant_allele_counts_%s.xls' % (TSP_FILEPATH_PLUGIN_DIR,bam['name'],bam['name'])) for bam in bams_processed if bam['status'] == 'completed']:
        combine_files(combinedfilename, myfile)
    printtime(' ')

def write_results_json(results_json):
    results_json['files'] = OUTPUT_FILES
    with open(os.path.join(TSP_FILEPATH_PLUGIN_DIR, 'results.json'), 'w') as out:
        json.dump(results_json, out, indent = 4)
    
def setup_run():
    os.chmod(TSP_FILEPATH_PLUGIN_DIR, 0775)  # TS-14652
    
    settings.configure(DEBUG=True, TEMPLATE_DEBUG=True, TEMPLATE_DIRS=((DIRNAME+'/templates'),))
    subprocess.call('rm -f %s/results.json' % TSP_FILEPATH_PLUGIN_DIR,shell=True)

    # Make links to js/css used for barcodes table and empty results page
    subprocess.call('ln -sf "%s/js" "%s"' % (DIRNAME,TSP_FILEPATH_PLUGIN_DIR),shell=True)
    subprocess.call('ln -sf "%s/css" "%s"' % (DIRNAME,TSP_FILEPATH_PLUGIN_DIR),shell=True)
    subprocess.call('ln -sf %s/scripts/*.php3 "%s"' % (DIRNAME,TSP_FILEPATH_PLUGIN_DIR),shell=True)    

def process_done(bams, bams_processed, status = None, error_msg = None, warning_msg = None):
    for bam in bams:
        if status is not None:
            bam['status'] = status
        if error_msg is not None:
            bam['error'].append(error_msg)
        if warning_msg is not None:
            bam['warning'].append(warning_msg)
        bams_processed.append(bam)    

def get_status_dict(process_status):
    status_dict = {'num_barcodes':       len(process_status['bams_will_be_processed']) + len(process_status['bams_filtered_out']),
                   'filtered_barcodes':  len(process_status['bams_filtered_out']),
                   'barcodes_processed': len(process_status['bams_processed']),
                   'queued_barcodes':    len(process_status['bams_will_be_processed']) - len(process_status['bams_processed']),
                   'barcodes_carried_out': len(process_status['bams_filtered_out']) + len(process_status['bams_processed']), }
    return status_dict

def generate_status_report(process_status, bams_in_progress, has_umt):
    output_dir = os.path.basename(TSP_FILEPATH_PLUGIN_DIR.rstrip('/'))
    render_context = {'barcode_data': process_status['bams_processed'] + bams_in_progress,
                      'output_dir': output_dir  ,
                      'status': get_status_dict(process_status),
                      'runinfo_pk': STARTPLUGIN_JSON['runinfo']['pk'],
                      'has_umt': has_umt
                      }
    
    with open(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_BLOCK), 'w') as out:
        out.write(render_to_string('processing_status.html', render_context))

def process_configuration(configuration, results_json, process_status):
    bams_processed = process_status['bams_processed']    
    # Abort the configuration if an error happened when getting the options and file check etc.
    if configuration['error']:
        printtime('ERROR: Fail to process configuration %s:' %configuration['name'])
        for error_message in configuration['error']:
            printtime('  ERROR: %s' %error_message)
        process_done(configuration['bams'], bams_processed, 'error', 'configuration error')
        return
    
    # write parameter json file
    write_parameters_file(configuration['options'])

    # Initial status of each bam file
    for bam in configuration['bams']:
        option_error_list = configuration['options'].serve_option('error', bam['name'])
        if option_error_list != []:
            bam['status'] = 'error'
            for error_msg in option_error_list:
                bam['error'].append(error_msg)
        for warning_msg in configuration['options'].serve_option('warning', bam['name']):
            bam['warning'].append(warning_msg)

        if not os.path.exists(bam['file']):
            bam['status'] = 'error'
            bam['error'].append('The bam file does not exist: %s' %bam['file'])
            
        if bam['status'] != 'error':
            bam['status'] = 'in_progress'
        print_options(configuration['options'], bam)
    
    # check multisample mode
    if configuration['multisample']:
        if not is_multisample_ok(configuration['option']):
            printtime('ERROR: Fail to process the configuration %s in the multisample mode.' %(configuration['name']))
            process_done(configuration['bams'], bams_processed, 'error', 'Fail to run multisample: Barcodes in the configuration do not use the same file or have error.')
            return

    # setup tmap server
    tmap_server_key = 0
    # Disable tmap server for now.
    '''
    random.seed(int(time.time()) + os.getpid())
    tmap_server_key = random.randint(1, 2147483647); # can not beyond the maximum integer in C.
    cmd = 'tmap server -k ' + str(tmap_server_key) + ' -c start -a -f "' + configuration['options']['reference_genome_fasta'] + '"'
    printtime(cmd)
    pid = subprocess.Popen(cmd, shell=True)
    time.sleep(15)
    if not pid.poll() is None:
        tmap_server_key = 0
    '''
    if tmap_server_key > 0:
        multisample_realign_fail = False
        # running tmap server, do realignment here
        for bam in configuration['bams']:        
            process_reference(configuration, bam, tmap_server_key)        
            if configuration['multisample'] and bam['status'] == 'error':
                multisample_realign_fail = True
                break
        cmd = 'tmap server -k ' + str(tmap_server_key) + ' -c stop'
        run_command(cmd, 'tmap server stop')
        if multisample_realign_fail:
            process_done(configuration['bams'], bams_processed, 'error', 'Fail to run multisample: one barcode fail to realign.')
            return


    if configuration['multisample']:
        if configuration['barcoded_run']:
            generate_status_report(process_status, configuration['bams'], configuration['options'].serve_option('has_umt'))
        if tmap_server_key == 0:
            # Not using tmap server. Do realignment here.
            for bam in configuration['bams']:
                process_reference(configuration, bam, tmap_server_key)
                if bam['status'] == 'error':
                    process_done(configuration['bams'], bams_processed, 'error', 'Fail to run multisample: one barcode fail to realign.')
                    return
        # Run variant_caller_pipeline and process results for multisample
        try:
            # One barcode has error and I claim all barcodes error.
            #TODO: A better handling for the case where some of the bam files have error.
            variant_caller_pipeline(configuration, configuration['bams'])
            split_results(configuration['options'], configuration['bams'])
        except:
            traceback.print_exc()
            process_done(configuration['bams'], bams_processed, 'error', 'Fail to run multisample: variant_caller_pipeline and/or split_results error.')
            return

        for bam in configuration['bams']:
            try:
                bam['summary'] = process_results(configuration, bam)
                load_results_json(configuration['options'], bam, results_json)
                bam['status'] = 'completed'
            except:
                traceback.print_exc()
                bam['status'] = 'error'
                bam['error'].append('Fail to process results.')
            bams_processed.append(bam)
    else:
        # Run variant_caller_pipeline and process results for non-multisample
        for bam in configuration['bams']:
            if configuration['barcoded_run']:
                generate_status_report(process_status, [bam, ], configuration['options'].serve_option('has_umt'))
            if tmap_server_key == 0:
                # Not using tmap server. Do realignment here to maximize the "barcode pipeline".                
                process_reference(configuration, bam, tmap_server_key)
            if bam['status'] == 'error':
                bams_processed.append(bam)
                continue
            try:
                variant_caller_pipeline(configuration, [bam, ])
                bam['summary'] = process_results(configuration, bam)
                load_results_json(configuration['options'], bam, results_json)
                bam['status'] = 'completed'
            except:
                traceback.print_exc()
                bam['status'] = 'error'
                bam['error'].append('Fail to run variant_caller_pipeline and/or process_results.')
            bams_processed.append(bam)

def get_consensus(value_list):
    '''
    is_consensus, consensus_value = get_consensus(value_list)
    is_consensus = True if all entries in value_list are the same, False otherwise.
    consensus_value = the consensus value. None if not is_consensus.
    '''
    if len(value_list) == 0:
        raise ValueError('The length of the input can not be zero.')    
    if len(value_list) == 1:
        return True, value_list[0]
    if value_list[:-1] == value_list[1:]:
        return True, value_list[0]
    else:
        return False, None
    
def get_global_options(configurations):
    '''
    Get the options to be shown in variantCaller.html and variantCaller_block.html
    '''
    barcode_specific = 'barcode specific'
    option_keys_of_interests = ['library_type', \
                                'reference_genome_name', 'has_targets', 'targets_name', 'has_hotspots', \
                                'hotspots_name', 'config_line1', 'run_name', 'has_umt']
    global_options = {}

    for config in configurations.itervalues():
        if 'configurations' in global_options:
            assert(global_options['configurations'] == config['configured_run'])
        else:
            global_options['configurations'] = config['configured_run']
        if 'barcoded_run' in global_options:
            assert(global_options['barcoded_run'] == config['barcoded_run'])
        else:
            global_options['barcoded_run'] = config['barcoded_run']            
            
    for key in option_keys_of_interests:
        value_list = [] # value_list is the consensuses of each configuration 
        for config in configurations.itervalues():
            # local_consensus is the consensus reached by the barcodes in a configuration
            try:
                is_local_consensus, local_consensus_value = config['options'].get_consensus_option_across_barcodes(key)
            except:
                is_local_consensus = False
            if not is_local_consensus:
                break
            value_list.append(local_consensus_value)
        consensus_value = None
        if is_local_consensus:
            is_consensus, consensus_value = get_consensus(value_list)
        else:
            is_consensus = False
        # Get the consensus of the consensus of the barcodes in each configuration
        global_options[key] = consensus_value if is_consensus else barcode_specific
        
    # Set the target name and hostspot name to be shown variantCaller.html and variantCaller_block.html
    if global_options['has_targets'] == False:
        global_options['targets_name'] = 'none'
    elif global_options['has_targets'] == barcode_specific:
        # At least one barcode has hotspots
        global_options['has_targets'] = True
    if global_options['has_hotspots'] == False:
        global_options['hotspots_name'] = 'none'
    elif global_options['has_hotspots'] == barcode_specific:
        # At least one barcode has hotspots
        global_options['has_hotspots'] = True
      
    return global_options
        
def generate_report_htmls(configurations, process_status):
    bams_processed = process_status['bams_processed']
    # Get the "global" options for generating the report html files. 
    global_options = get_global_options(configurations)

    # Generate the report html files
    error_barcodes = [bam['name'] for bam in bams_processed if bam['status'] == 'error']

    if len(error_barcodes) == len(bams_processed):
        barcode_text = 'all barcodes' if len(bams_processed) > 0 else 'the bam file'
        generate_incomplete_report_page(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_RESULTS), 'ERROR: The plugin fails to process %s. Please check Log File for details.' %barcode_text, global_options['run_name'])
        generate_incomplete_report_block_page(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_BLOCK), 'The plugin fails to process %s. Please check Log File for details.' %barcode_text)    
        return
    if not PLUGIN_DEV_SKIP_VARIANT_CALLING:
        generate_download_files(global_options['run_name'], bams_processed)        
    error_msg = ''
    if len(error_barcodes) > 0:
        error_msg = 'The plugin fails to process %d barcode%s. Please check Log File for details.' %(len(error_barcodes), 's' if len(error_barcodes) > 1 else '')
    # All warning messages
    all_warnings = []
    warning_msg = ''
    for config in configurations.itervalues():
        all_warnings += config['warning'] 
        for bam in config['bams']:
            all_warnings += bam['warning']
            all_warnings += config['options'].serve_option('warning', bam['name'])
    if len(all_warnings) > 0:
        if len(process_status['bams_filtered_out']) == len(all_warnings):
            num_non_dna_barcodes = len([None for w in all_warnings if 'Nucleotide type is not DNA.' in w])
            num_low_read_counts_barcodes = len([None for w in all_warnings if 'read counts < minimum read counts' in w])
            warning_msg = ''
            if num_non_dna_barcodes > 0:
                warning_msg += '%d barcode%s filtered out because of non-DNA nucleotide type.' %(num_non_dna_barcodes, 's are' if num_non_dna_barcodes > 1 else ' is')            
            if num_low_read_counts_barcodes > 0:
                warning_msg += '%d barcode%s filtered out because of low read counts (<%d).' %(num_low_read_counts_barcodes, 's are' if num_low_read_counts_barcodes > 1 else ' is', BCFILE_MIN_READS)
        else:
            warning_msg = 'The plugin encounters %d warning%s. Please check Log File for details.' %(len(all_warnings), 's' if len(all_warnings) > 1 else '')

    generate_barcode_links_block(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_BLOCK), process_status, global_options, error_msg, warning_msg)
    if global_options['barcoded_run']:
        generate_barcode_links_page(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_RESULTS), process_status, global_options, error_msg, warning_msg)

def plugin_main():
    global PLUGIN_DEV_SKIP_VARIANT_CALLING
    global DIRNAME
    global TSP_URLPATH_PLUGIN_DIR
    global ANALYSIS_DIR
    global TSP_FILEPATH_PLUGIN_DIR
    global STARTPLUGIN_JSON
    global BARCODES_JSON
    global OUTPUT_FILES
    global TVCUTILS
    global TMAPBIN

    parser = OptionParser()
    parser.add_option('-d', '--install-dir', help='Directory containing plugin files', dest='install_dir')
    parser.add_option('-o', '--output-dir', help='Directory for results files', dest='output_dir')
    parser.add_option('-u', '--output-url', help='URL matching the output directory', dest='output_url')
    parser.add_option('-r', '--report-dir', help='Directory containing analysis report files', dest='report_dir')
    parser.add_option('-s', '--skip-tvc', help='(debug) Skip variant calling and reuse existing results', dest='skip_tvc', action="store_true", default=False)
    (plugin_main_options, args) = parser.parse_args()

    if len(sys.argv) < 2:
        parser.print_help()
        sys.exit(0)

    DIRNAME                     = plugin_main_options.install_dir    #os.environ['DIRNAME']         # home directory for the plugin files
    TSP_FILEPATH_PLUGIN_DIR     = plugin_main_options.output_dir     #os.environ['TSP_FILEPATH_PLUGIN_DIR'] # target plugin results directory
    ANALYSIS_DIR                = plugin_main_options.report_dir     #os.environ['ANALYSIS_DIR'] # main report directory
    TSP_URLPATH_PLUGIN_DIR      = plugin_main_options.output_url
    PLUGIN_DEV_SKIP_VARIANT_CALLING = plugin_main_options.skip_tvc
    OUTPUT_FILES = []
    
    # XXX Global variables dtoring path to executables
    TVCUTILS = os.path.join(os.path.join(DIRNAME, 'bin'), 'tvcutils')
    if not os.path.isfile(TVCUTILS):
        TVCUTILS = 'tvcutils'
    TMAPBIN = os.path.join(os.path.join(DIRNAME, 'bin'), 'tmap')
    if not os.path.isfile(TMAPBIN):
       TMAPBIN = 'tmap'
    
    if PLUGIN_DEV_SKIP_VARIANT_CALLING:
        os.symlink = lambda source, dest: None
    
    setup_run()

    printtime('')
    printtime('Variant Caller Plugin started')
    printtime('')

    printtime('Loading ' + os.path.join(TSP_FILEPATH_PLUGIN_DIR,'startplugin.json'))
    try:
        with open(os.path.join(TSP_FILEPATH_PLUGIN_DIR,'startplugin.json'), 'r') as json_file:
            STARTPLUGIN_JSON = json.load(json_file,parse_float=str)
    except:
        printtime('ERROR: Failed to load and parse startplugin.json')
        return 1
    if STARTPLUGIN_JSON.get('pluginconfig', {}) == {}:
        printtime('ERROR: The plugin is not configured. Perhaps select the plugin in the plan w/o configuring it?')
        return 1
    
    printtime('Loading ' + os.path.join(TSP_FILEPATH_PLUGIN_DIR, 'barcodes.json'))
    try:
        with open(os.path.join(TSP_FILEPATH_PLUGIN_DIR, 'barcodes.json'), 'r') as json_file:
            BARCODES_JSON = json.load(json_file)
    except:
        printtime('ERROR: Failed to load and parse barcodes.json')
        return 1
   
    # Get the plugin running modes that are shared by all configurations
    barcoded_run, configured_run, start_mode, multisample = get_plugin_mode()

    if not barcoded_run and len(BARCODES_JSON.keys()) > 1:
        printtime('ERROR: barcodes.json has contradiction that multiple barcodes are listed while a barcode named %s' %NONBARCODED)
        return 1
    
    if multisample:
        printtime('ERROR: VariantCaller Plugin currently does not support multisample.')
        return 1

    configurations, process_status = get_configurations(barcoded_run, configured_run, start_mode, multisample)

    results_json = setup_results_json(barcoded_run)

    for configuration in configurations.itervalues():
        configuration['options'] = ConfigureOptionsManager(configuration)
        process_configuration(configuration, results_json, process_status)

    # No bam file actually being processed.
    if process_status['bams_processed'] == []:
        generate_incomplete_report_page(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_RESULTS), 'WARNING: No bam file was processed by the plugin - please check Log File for details.', STARTPLUGIN_JSON['expmeta'].get('run_name','Current run'))
        generate_incomplete_report_block_page(os.path.join(TSP_FILEPATH_PLUGIN_DIR, HTML_BLOCK), '' , 'No bam file was processed by the plugin - please check Log File for details.')                
        printtime('WARNING: No bam file was processed by the plugin!')
    else:
        generate_report_htmls(configurations, process_status)
    
    printtime('')
    printtime('Final processing status:')
    has_error = False
    for configuration in configurations.itervalues():
        for warning in configuration['warning']:
            printtime('WARNING: %s' %warning)
        for bam in configuration['bams']:
            printtime('%s: %s' %(bam['name'] if barcoded_run else 'rawlib.bam', bam['status']))
            for warning_msg in bam['warning']:
                printtime('  WARNING: %s' %warning_msg)
            for error_msg in bam['error']:
                printtime('  ERROR: %s' %error_msg)
            if bam['status'] == 'error':
                has_error = True
    printtime('')
    
    write_results_json(results_json)

    if has_error:
        return 1
    
    printtime('')
    printtime('Variant Caller Plugin complete')
    printtime('')

    return 0

if __name__ == "__main__":

    exit(plugin_main())


